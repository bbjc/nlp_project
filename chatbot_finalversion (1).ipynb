{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e07e0b2c-1642-465b-b386-d86c76494dde",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Chatbot for game recommandation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "024b161a-d527-4956-8580-03cb6810bf18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install langchain\n",
    "#!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96887d09-f8e9-484a-be59-d83a21002a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip uninstall openai langchain langchain_openai -y\n",
    "#!pip install openai langchain langchain_openai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3ff55db-13e7-4045-b701-e475b6aab091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip show typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c617d1eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7711c08f-b513-4618-8bd6-fd6cb0c5db23",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68ddd0d5-59b7-40ed-b613-407973ef75b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2', cache_folder=\"./cache\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7733c8dd-57bf-4798-9fec-0f2f9d7041a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Charger les jeux IGDB\n",
    "#with open(\"igdb_games.json\", \"r\") as f:\n",
    "    #games_data = json.load(f)\n",
    "\n",
    "#for game in games_data:\n",
    " #   game[\"embedding\"] = embedding_model.encode(game.get(\"summary\", \"No description\")).tolist()  \n",
    "\n",
    "# Sauvegarde en JSON\n",
    "#with open(\"igdb_games_embedding.json\", \"w\") as f:\n",
    "   # json.dump(games_data, f, indent=4)  \n",
    "\n",
    "#print(\"Base de donn√©es des jeux enregistr√©e avec embeddings !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73946ad8-26e0-45f4-bb06-b5c418728006",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08f1bbae-916f-4480-bdcb-0081b870808b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load steam reviews\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "steam_reviews = pd.read_csv(\"./steam_reviews.csv\", names=['id', 'app_id', 'content', 'author_id', 'sentiment'], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d04b84c1-6d9b-47a6-847a-2c51a8364d2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>At least its a counter strike</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uh    So far my playthrough has not been great...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Better mechanics than cs</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>buggy mess and NOT fun to play at all</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Whoever came up with this  is gonna fucking ge...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content sentiment\n",
       "0               At least its a counter strike         negative\n",
       "1  Uh    So far my playthrough has not been great...  negative\n",
       "2                          Better mechanics than cs   negative\n",
       "3              buggy mess and NOT fun to play at all  negative\n",
       "4  Whoever came up with this  is gonna fucking ge...  negative"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the reviews\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    # remove html tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # remove @mentions\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text)\n",
    "\n",
    "    # remove urls\n",
    "    text = re.sub(r'https?://[A-Za-z0-9./]+', '', text)\n",
    "\n",
    "    # keep only alphanumeric characters\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "def remove_special_chars(tokens):\n",
    "    return [word for word in tokens if word.isalnum()]\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(tokens):\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "def preprocess(tokens):\n",
    "    # return lemmatize(remove_special_chars(remove_stopwords(tokens)))\n",
    "    return lemmatize(remove_special_chars(tokens))\n",
    "\n",
    "steam_reviews = steam_reviews[['content', 'sentiment']]\n",
    "steam_reviews['content'] = steam_reviews['content'].apply(clean_text)\n",
    "steam_reviews['sentiment'] = steam_reviews['sentiment'].apply(lambda x: str(x).lower())\n",
    "steam_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98be907f-2f0d-461e-b21d-9a9b25cda075",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201151, 97755)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use tfidf to vectorize the reviews\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df = steam_reviews\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=None, \n",
    "                        lowercase=False,\n",
    "                        preprocessor=None)\n",
    "\n",
    "X = tfidf.fit_transform(df['content'])\n",
    "X.shape # (n_samples, n_features) = (201151, 97755)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "111d629d-eda1-4a32-a2de-d0d1a18ff441",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8424872733057588"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the logistic regression model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y = df['sentiment'] # target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr.fit(X_train,y_train) # fit the model\n",
    "preds = lr.predict(X_test) # make predictions\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(preds,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71633586-4b62-4fb5-bd0b-a787da751326",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('positive', 0.9627468844601628)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the sentiment of a review\n",
    "def predict_sentiment(review):\n",
    "    review = clean_text(review)\n",
    "    review = tfidf.transform([review])\n",
    "    sentiment = lr.predict(review)[0]\n",
    "    proba = lr.predict_proba(review)[0][0 if sentiment == 'negative' else 1]\n",
    "    return sentiment, proba\n",
    "\n",
    "predict_sentiment(\"I love game about war\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67d318b-2df3-4b84-942e-1281aa37032f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73f33dbc-a25c-4d29-850f-838ef5ca1e16",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m2025-03-25 20:50:46.815641: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-25 20:50:46.815731: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-25 20:50:46.818038: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-25 20:50:46.827821: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-25 20:50:48.094305: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-03-25 20:50:49.591112: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-25 20:50:49.591634: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-25 20:50:49.591835: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "Collecting en-core-web-md==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.6.0/en_core_web_md-3.6.0-py3-none-any.whl (42.8 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from en-core-web-md==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.11.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.26.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (69.0.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.11/dist-packages (from pathy>=0.10.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2020.6.20)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.11/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.1.4)\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "#!pip install fuzzywuzzy\n",
    "#!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "56fd4d63-cc2c-4d91-93cc-adbdb4813f60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "#python -m spacy download en_core_web_md\n",
    "from fuzzywuzzy import process  # Pour la recherche approximative\n",
    "\n",
    "# Charger le fichier JSON\n",
    "with open(\"igdb_games_embedding.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    games_data = json.load(file)\n",
    "    \n",
    "sample_games = random.sample(games_data, 1000)\n",
    "\n",
    "# Initialiser les listes\n",
    "games_db = []\n",
    "categories_db = set()  # Utiliser un set pour √©viter les doublons\n",
    "\n",
    "# Parcourir les jeux dans le JSON\n",
    "for game in sample_games:\n",
    "    if \"name\" in game:\n",
    "        games_db.append(game[\"name\"])  # Ajouter le nom du jeu\n",
    "    \n",
    "    if \"genres\" in game and isinstance(game[\"genres\"], list):\n",
    "        for genre in game[\"genres\"]:\n",
    "            if \"name\" in genre:  # V√©rifier si le nom du genre existe\n",
    "                categories_db.add(genre[\"name\"])\n",
    "\n",
    "# Convertir en liste finale\n",
    "categories_db = list(categories_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d220825b-d85a-4f71-a368-7379e3cc3060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Afficher le r√©sultat\n",
    "#print(\"Jeux d√©tect√©s:\", games_db[:10])\n",
    "#print(\"Cat√©gories d√©tect√©es:\", categories_db[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2286e0ad-4670-4fc8-9c21-750697a05cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Charger le mod√®le spaCy\n",
    "nlp = spacy.load(\"en_core_web_md\")  # ou \"fr_core_news_md\" pour le fran√ßais\n",
    "\n",
    "# Initialisation du PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
    "\n",
    "game_to_use=games_db\n",
    "# Ajouter les noms de jeux et cat√©gories au matcher\n",
    "patterns_games = [nlp(game) for game in game_to_use]\n",
    "patterns_categories = [nlp(cat) for cat in categories_db]\n",
    "\n",
    "matcher.add(\"GAME\", patterns_games)\n",
    "matcher.add(\"CATEGORY\", patterns_categories)\n",
    "\n",
    "def fuzzy_match_game(text, threshold=80):\n",
    "    \"\"\"\n",
    "    Recherche un jeu dans la base avec tol√©rance aux fautes de frappe.\n",
    "    Renvoie le jeu correspondant si la similarit√© est sup√©rieure au seuil.\n",
    "    \"\"\"\n",
    "    best_match, score = process.extractOne(text, game_to_use) if text else (None, 0)\n",
    "    return best_match if score >= threshold else None\n",
    "\n",
    "def extract_games_and_categories(text):\n",
    "    \"\"\"\n",
    "    D√©tecte les jeux et cat√©gories dans un texte en combinant PhraseMatcher et fuzzy matching.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)  # Tokenisation\n",
    "    matches = matcher(doc)  # Recherche des correspondances exactes\n",
    "    \n",
    "    extracted_info = {\"games\": set(), \"categories\": set()}\n",
    "    matched_texts = set()  # Pour √©viter les doublons\n",
    "\n",
    "    # Recherche des jeux et cat√©gories exacts avec PhraseMatcher\n",
    "    for match_id, start, end in matches:\n",
    "        label = nlp.vocab.strings[match_id]\n",
    "        entity = doc[start:end].text\n",
    "        \n",
    "        if label == \"GAME\":\n",
    "            extracted_info[\"games\"].add(entity)\n",
    "        elif label == \"CATEGORY\":\n",
    "            extracted_info[\"categories\"].add(entity)\n",
    "        \n",
    "        matched_texts.add(entity.lower())\n",
    "\n",
    "    # üîç Recherche des jeux approximatifs avec filtre\n",
    "    for token in doc:\n",
    "        if (token.text.lower() not in matched_texts  # √âviter les doublons\n",
    "            and not token.is_punct  # Ignorer la ponctuation\n",
    "            and not token.is_stop  # Ignorer les mots vides (\"le\", \"et\", \"de\", etc.)\n",
    "            and len(token.text) > 2):  # Ignorer les mots trop courts\n",
    "        \n",
    "            fuzzy_game = fuzzy_match_game(token.text)\n",
    "            if fuzzy_game:\n",
    "                extracted_info[\"games\"].add(fuzzy_game)\n",
    "    \n",
    "    return extracted_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ea7cc2ed-01fb-4c46-a0bd-44bfa5fd92be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'games': {'Jrago II: Guardians of Eden', 'Action Fighter', 'Quiz Magic Academy 6', 'Shin Megami Tensei J', 'Magic of Spring', 'Flowering Nightshade', 'Dark Fantasy: Epic Jigsaw Puzzle', 'AIR Summer Solstice'}, 'categories': set()}\n"
     ]
    }
   ],
   "source": [
    "#text = \"J'adore Elden Ring, c'est un excellent RPG. Je cherche un jeu d'action qui ressemble √† Hades. J'ai aussi aim√© Dark Sols.\"\n",
    "\n",
    "#result = extract_games_and_categories(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e50697d-2c6f-436a-ada6-d3a3d3de8719",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Function for recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ae245b6a-eee6-4a84-a1e2-f9573568eb73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "import random\n",
    "\n",
    "# Fonction de recommandation bas√©e sur la similarit√©\n",
    "def recommend_game(user_query):\n",
    "    #extract infos\n",
    "    extract = extract_games_and_categories(user_query)\n",
    "    # R√©cup√©rer les descriptions des jeux extraits\n",
    "    game_descriptions = {}\n",
    "    for game_name in extract['games']:\n",
    "        for game in sample_games:\n",
    "            if game['name'] == game_name:\n",
    "                game_descriptions[game_name] = game['summary']\n",
    "\n",
    "\n",
    "    # Sentiment analysis\n",
    "    sentiment, proba = predict_sentiment(user_query)\n",
    "\n",
    "    recommand_similar_game = True # default\n",
    "    if sentiment=='negative' and proba > 0.70:\n",
    "        recommand_similar_game = False\n",
    "        \n",
    "    if game_descriptions:\n",
    "        description_query = \" \".join(game_descriptions.values())  # Combine toutes les descriptions\n",
    "        user_query = description_query\n",
    "    query_embedding = embedding_model.encode(user_query)\n",
    "    similarities = [\n",
    "        (game[\"name\"], 1 - cosine(query_embedding, game[\"embedding\"]), game.get(\"rating\", 0))\n",
    "        for game in sample_games if \"embedding\" in game\n",
    "    ]\n",
    "\n",
    "    if recommand_similar_game:\n",
    "        similarities.sort(key=lambda x:(x[1], x[2]), reverse=True)\n",
    "    else:\n",
    "        similarities.sort(key=lambda x: (x[1], x[2]), reverse=False)\n",
    "\n",
    "    return similarities[:3]\n",
    "\n",
    "# Test\n",
    "#user_input = \"I don't love war game\"\n",
    "#print(\"Jeux recommand√©s :\", recommend_game(user_input))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1f1bd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5eb0cbd-dfea-422b-8365-c8bbf5d9742d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChatSession:\n",
    "    def __init__(self, memsize, llm):\n",
    "        self.llm = llm\n",
    "        self.memsize = memsize\n",
    "        self.history = []\n",
    "        self.llmID = \"ASSISTANT:\"\n",
    "        self.userID = \"USER:\"\n",
    "                \n",
    "    def summarizeStrategy(self):\n",
    "        summaryPrompt = \"R√©sume la conversation suivante en gardant un maximum d'informations fournies par \" + self.userID + \" :\\n\"\n",
    "        lastMessage, lastMessageLength = self.history[-1]\n",
    "        history = \"\"\n",
    "        for m, l in self.history[:-1]:\n",
    "            history += m + \"\\n\"\n",
    "        summary = self.llm.invoke([HumanMessage(content=summaryPrompt + \"\\n\" + history)]).content\n",
    "        summaryLength = self.estimateLength(summary)\n",
    "        if summaryLength + lastMessageLength > self.memsize:\n",
    "            self.fifoStrategy()\n",
    "            return\n",
    "        self.history = [(summary, summaryLength), (lastMessage, lastMessageLength)]\n",
    "    \n",
    "    def fifoStrategy(self):\n",
    "        while self.historyLength() > self.memsize:\n",
    "            self.history = self.history[1:]\n",
    "\n",
    "    def historyLength(self):\n",
    "        return sum(length for _, length in self.history)\n",
    "\n",
    "    def estimateLength(self, text):\n",
    "        return self.llm.get_num_tokens(text)\n",
    "\n",
    "    def addToHistory(self, prompt):\n",
    "        self.history.append((prompt, self.estimateLength(prompt)))\n",
    "        if self.historyLength() > self.memsize:\n",
    "            self.summarizeStrategy()\n",
    "\n",
    "    def chat(self, prompt):\n",
    "        self.addToHistory(self.userID + \" \" + prompt)\n",
    "\n",
    "        recommendations = recommend_game(prompt)\n",
    "        games_list = \", \".join([game[0] for game in recommendations])\n",
    "\n",
    "        chat_prompt = f\"\"\"\n",
    "        L'utilisateur cherche un jeu correspondant √† : \"{prompt}\".\n",
    "        Voici les jeux recommand√©s : {games_list}.\n",
    "        Formule une r√©ponse naturelle et engageante.\n",
    "        \"\"\"\n",
    "\n",
    "        fullPrompt = 'Historique de conversation :\\n'\n",
    "        for msg, _ in self.history:\n",
    "            fullPrompt += msg + \"\\n\"\n",
    "\n",
    "        fullPrompt += \"\\n\" + chat_prompt\n",
    "\n",
    "        resp = self.llm.invoke([HumanMessage(content=fullPrompt)])\n",
    "        content = resp.content\n",
    "        if content.startswith(self.llmID + \": \"):\n",
    "            content = content[len(self.llmID + \": \"):]\n",
    "\n",
    "        self.addToHistory(self.llmID + \" \" + content)\n",
    "        return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8ca7bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " llm = ChatOpenAI(\n",
    "        openai_api_key=\"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\",\n",
    "        openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "        model_name=\"mistralai/mistral-small-3.1-24b-instruct:free\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d64b33c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONTEXT_LENGTH = 500  \n",
    "session = ChatSession(CONTEXT_LENGTH, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0242fe-e8fd-4a5d-b162-08ed1c52525f",
   "metadata": {},
   "source": [
    "### Use Of chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78cb85ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Welcome to the video game recommendation chatbot with memory!\n",
      "\n",
      " Ask me a question (e.g.: ‚ÄúI want an RPG with a good scenario‚Äù).\n",
      "\n",
      " Type ‚Äúexit‚Äù to quit.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üë§ Vous :  I want a adventure game like naruto or call of duty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Bot : Salut ! Si tu cherches un jeu d'aventure au style similaire √† Naruto ou Call of Duty, je te propose de jeter un ≈ìil √† ces trois options :\n",
      "\n",
      "1. **Adventures of the Cat Leopold** : Bien que ce ne soit pas exactement Naruto, ce jeu offre une aventure pleine d'action et des combats int√©ressants. Tu devras explorer un vaste monde tout en accomplissant des missions captivantes.\n",
      "\n",
      "2. **Munlay Online** : Il combine des √©l√©ments de combat en √©quipe √† la mani√®re de Call of Duty, mais dans un environnement fantastique. C'est parfait pour ceux qui aiment des d√©fis coop√©ratifs et des combats strat√©giques.\n",
      "\n",
      "3. **Piworld** : Il te plaira si tu cherches des aventures qui m√©langent exploration et combat. C'est un jeu o√π chaque d√©cision compte et o√π tu devras utiliser tes comp√©tences pour progresser.\n",
      "\n",
      "Ces jeux offrent chacun une exp√©rience unique qui, je l'esp√®re, r√©pondra √† ton envie d'aventure et d'action ! Si tu as besoin de plus de recommandations ou de pr√©cisions, fais-le moi savoir !\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üë§ Vous :  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√Ä bient√¥t !\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Welcome to the video game recommendation chatbot with memory!\")\n",
    "print(\"\\n Ask me a question (e.g.: ‚ÄúI want an RPG with a good scenario‚Äù).\")\n",
    "print(\"\\n Type ‚Äúexit‚Äù to quit.\\n\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"üë§ Vous : \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"√Ä bient√¥t !\")\n",
    "        break\n",
    "    \n",
    "    response = session.chat(user_input)\n",
    "    print(f\"ü§ñ Bot : {response}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
