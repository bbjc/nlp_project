{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e07e0b2c-1642-465b-b386-d86c76494dde",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Chatbot for game recommandation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "024b161a-d527-4956-8580-03cb6810bf18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install langchain\n",
    "#!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96887d09-f8e9-484a-be59-d83a21002a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip uninstall openai langchain langchain_openai -y\n",
    "#!pip install openai langchain langchain_openai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3ff55db-13e7-4045-b701-e475b6aab091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip show typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c617d1eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7711c08f-b513-4618-8bd6-fd6cb0c5db23",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68ddd0d5-59b7-40ed-b613-407973ef75b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2', cache_folder=\"./cache\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7733c8dd-57bf-4798-9fec-0f2f9d7041a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Charger les jeux IGDB\n",
    "#with open(\"igdb_games.json\", \"r\") as f:\n",
    "    #games_data = json.load(f)\n",
    "\n",
    "#for game in games_data:\n",
    " #   game[\"embedding\"] = embedding_model.encode(game.get(\"summary\", \"No description\")).tolist()  \n",
    "\n",
    "# Sauvegarde en JSON\n",
    "#with open(\"igdb_games_embedding.json\", \"w\") as f:\n",
    "   # json.dump(games_data, f, indent=4)  \n",
    "\n",
    "#print(\"Base de données des jeux enregistrée avec embeddings !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73946ad8-26e0-45f4-bb06-b5c418728006",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08f1bbae-916f-4480-bdcb-0081b870808b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load steam reviews\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "steam_reviews = pd.read_csv(\"./steam_reviews.csv\", names=['id', 'app_id', 'content', 'author_id', 'sentiment'], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d04b84c1-6d9b-47a6-847a-2c51a8364d2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>At least its a counter strike</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uh    So far my playthrough has not been great...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Better mechanics than cs</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>buggy mess and NOT fun to play at all</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Whoever came up with this  is gonna fucking ge...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content sentiment\n",
       "0               At least its a counter strike         negative\n",
       "1  Uh    So far my playthrough has not been great...  negative\n",
       "2                          Better mechanics than cs   negative\n",
       "3              buggy mess and NOT fun to play at all  negative\n",
       "4  Whoever came up with this  is gonna fucking ge...  negative"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the reviews\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    # remove html tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # remove @mentions\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text)\n",
    "\n",
    "    # remove urls\n",
    "    text = re.sub(r'https?://[A-Za-z0-9./]+', '', text)\n",
    "\n",
    "    # keep only alphanumeric characters\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "def remove_special_chars(tokens):\n",
    "    return [word for word in tokens if word.isalnum()]\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(tokens):\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "def preprocess(tokens):\n",
    "    # return lemmatize(remove_special_chars(remove_stopwords(tokens)))\n",
    "    return lemmatize(remove_special_chars(tokens))\n",
    "\n",
    "steam_reviews = steam_reviews[['content', 'sentiment']]\n",
    "steam_reviews['content'] = steam_reviews['content'].apply(clean_text)\n",
    "steam_reviews['sentiment'] = steam_reviews['sentiment'].apply(lambda x: str(x).lower())\n",
    "steam_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98be907f-2f0d-461e-b21d-9a9b25cda075",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201151, 97755)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use tfidf to vectorize the reviews\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df = steam_reviews\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=None, \n",
    "                        lowercase=False,\n",
    "                        preprocessor=None)\n",
    "\n",
    "X = tfidf.fit_transform(df['content'])\n",
    "X.shape # (n_samples, n_features) = (201151, 97755)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "111d629d-eda1-4a32-a2de-d0d1a18ff441",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8424872733057588"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the logistic regression model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y = df['sentiment'] # target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr.fit(X_train,y_train) # fit the model\n",
    "preds = lr.predict(X_test) # make predictions\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(preds,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71633586-4b62-4fb5-bd0b-a787da751326",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('positive', 0.9627468844601628)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the sentiment of a review\n",
    "def predict_sentiment(review):\n",
    "    review = clean_text(review)\n",
    "    review = tfidf.transform([review])\n",
    "    sentiment = lr.predict(review)[0]\n",
    "    proba = lr.predict_proba(review)[0][0 if sentiment == 'negative' else 1]\n",
    "    return sentiment, proba\n",
    "\n",
    "predict_sentiment(\"I love game about war\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67d318b-2df3-4b84-942e-1281aa37032f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73f33dbc-a25c-4d29-850f-838ef5ca1e16",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m2025-03-25 20:50:46.815641: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-25 20:50:46.815731: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-25 20:50:46.818038: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-25 20:50:46.827821: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-25 20:50:48.094305: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-03-25 20:50:49.591112: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-25 20:50:49.591634: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-25 20:50:49.591835: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "Collecting en-core-web-md==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.6.0/en_core_web_md-3.6.0-py3-none-any.whl (42.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from en-core-web-md==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.11.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.26.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (69.0.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.11/dist-packages (from pathy>=0.10.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2020.6.20)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.11/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.1.4)\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "#!pip install fuzzywuzzy\n",
    "#!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "56fd4d63-cc2c-4d91-93cc-adbdb4813f60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "#python -m spacy download en_core_web_md\n",
    "from fuzzywuzzy import process  # Pour la recherche approximative\n",
    "\n",
    "# Charger le fichier JSON\n",
    "with open(\"igdb_games_embedding.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    games_data = json.load(file)\n",
    "    \n",
    "sample_games = random.sample(games_data, 1000)\n",
    "\n",
    "# Initialiser les listes\n",
    "games_db = []\n",
    "categories_db = set()  # Utiliser un set pour éviter les doublons\n",
    "\n",
    "# Parcourir les jeux dans le JSON\n",
    "for game in sample_games:\n",
    "    if \"name\" in game:\n",
    "        games_db.append(game[\"name\"])  # Ajouter le nom du jeu\n",
    "    \n",
    "    if \"genres\" in game and isinstance(game[\"genres\"], list):\n",
    "        for genre in game[\"genres\"]:\n",
    "            if \"name\" in genre:  # Vérifier si le nom du genre existe\n",
    "                categories_db.add(genre[\"name\"])\n",
    "\n",
    "# Convertir en liste finale\n",
    "categories_db = list(categories_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d220825b-d85a-4f71-a368-7379e3cc3060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Afficher le résultat\n",
    "#print(\"Jeux détectés:\", games_db[:10])\n",
    "#print(\"Catégories détectées:\", categories_db[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2286e0ad-4670-4fc8-9c21-750697a05cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Charger le modèle spaCy\n",
    "nlp = spacy.load(\"en_core_web_md\")  # ou \"fr_core_news_md\" pour le français\n",
    "\n",
    "# Initialisation du PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
    "\n",
    "game_to_use=games_db\n",
    "# Ajouter les noms de jeux et catégories au matcher\n",
    "patterns_games = [nlp(game) for game in game_to_use]\n",
    "patterns_categories = [nlp(cat) for cat in categories_db]\n",
    "\n",
    "matcher.add(\"GAME\", patterns_games)\n",
    "matcher.add(\"CATEGORY\", patterns_categories)\n",
    "\n",
    "def fuzzy_match_game(text, threshold=80):\n",
    "    \"\"\"\n",
    "    Recherche un jeu dans la base avec tolérance aux fautes de frappe.\n",
    "    Renvoie le jeu correspondant si la similarité est supérieure au seuil.\n",
    "    \"\"\"\n",
    "    best_match, score = process.extractOne(text, game_to_use) if text else (None, 0)\n",
    "    return best_match if score >= threshold else None\n",
    "\n",
    "def extract_games_and_categories(text):\n",
    "    \"\"\"\n",
    "    Détecte les jeux et catégories dans un texte en combinant PhraseMatcher et fuzzy matching.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)  # Tokenisation\n",
    "    matches = matcher(doc)  # Recherche des correspondances exactes\n",
    "    \n",
    "    extracted_info = {\"games\": set(), \"categories\": set()}\n",
    "    matched_texts = set()  # Pour éviter les doublons\n",
    "\n",
    "    # Recherche des jeux et catégories exacts avec PhraseMatcher\n",
    "    for match_id, start, end in matches:\n",
    "        label = nlp.vocab.strings[match_id]\n",
    "        entity = doc[start:end].text\n",
    "        \n",
    "        if label == \"GAME\":\n",
    "            extracted_info[\"games\"].add(entity)\n",
    "        elif label == \"CATEGORY\":\n",
    "            extracted_info[\"categories\"].add(entity)\n",
    "        \n",
    "        matched_texts.add(entity.lower())\n",
    "\n",
    "    # 🔍 Recherche des jeux approximatifs avec filtre\n",
    "    for token in doc:\n",
    "        if (token.text.lower() not in matched_texts  # Éviter les doublons\n",
    "            and not token.is_punct  # Ignorer la ponctuation\n",
    "            and not token.is_stop  # Ignorer les mots vides (\"le\", \"et\", \"de\", etc.)\n",
    "            and len(token.text) > 2):  # Ignorer les mots trop courts\n",
    "        \n",
    "            fuzzy_game = fuzzy_match_game(token.text)\n",
    "            if fuzzy_game:\n",
    "                extracted_info[\"games\"].add(fuzzy_game)\n",
    "    \n",
    "    return extracted_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ea7cc2ed-01fb-4c46-a0bd-44bfa5fd92be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'games': {'Jrago II: Guardians of Eden', 'Action Fighter', 'Quiz Magic Academy 6', 'Shin Megami Tensei J', 'Magic of Spring', 'Flowering Nightshade', 'Dark Fantasy: Epic Jigsaw Puzzle', 'AIR Summer Solstice'}, 'categories': set()}\n"
     ]
    }
   ],
   "source": [
    "#text = \"J'adore Elden Ring, c'est un excellent RPG. Je cherche un jeu d'action qui ressemble à Hades. J'ai aussi aimé Dark Sols.\"\n",
    "\n",
    "#result = extract_games_and_categories(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e50697d-2c6f-436a-ada6-d3a3d3de8719",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Function for recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ae245b6a-eee6-4a84-a1e2-f9573568eb73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "import random\n",
    "\n",
    "# Fonction de recommandation basée sur la similarité\n",
    "def recommend_game(user_query):\n",
    "    #extract infos\n",
    "    extract = extract_games_and_categories(user_query)\n",
    "    # Récupérer les descriptions des jeux extraits\n",
    "    game_descriptions = {}\n",
    "    for game_name in extract['games']:\n",
    "        for game in sample_games:\n",
    "            if game['name'] == game_name:\n",
    "                game_descriptions[game_name] = game['summary']\n",
    "\n",
    "\n",
    "    # Sentiment analysis\n",
    "    sentiment, proba = predict_sentiment(user_query)\n",
    "\n",
    "    recommand_similar_game = True # default\n",
    "    if sentiment=='negative' and proba > 0.70:\n",
    "        recommand_similar_game = False\n",
    "        \n",
    "    if game_descriptions:\n",
    "        description_query = \" \".join(game_descriptions.values())  # Combine toutes les descriptions\n",
    "        user_query = description_query\n",
    "    query_embedding = embedding_model.encode(user_query)\n",
    "    similarities = [\n",
    "        (game[\"name\"], 1 - cosine(query_embedding, game[\"embedding\"]), game.get(\"rating\", 0))\n",
    "        for game in sample_games if \"embedding\" in game\n",
    "    ]\n",
    "\n",
    "    if recommand_similar_game:\n",
    "        similarities.sort(key=lambda x:(x[1], x[2]), reverse=True)\n",
    "    else:\n",
    "        similarities.sort(key=lambda x: (x[1], x[2]), reverse=False)\n",
    "\n",
    "    return similarities[:3]\n",
    "\n",
    "# Test\n",
    "#user_input = \"I don't love war game\"\n",
    "#print(\"Jeux recommandés :\", recommend_game(user_input))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1f1bd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5eb0cbd-dfea-422b-8365-c8bbf5d9742d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChatSession:\n",
    "    def __init__(self, memsize, llm):\n",
    "        self.llm = llm\n",
    "        self.memsize = memsize\n",
    "        self.history = []\n",
    "        self.llmID = \"ASSISTANT:\"\n",
    "        self.userID = \"USER:\"\n",
    "                \n",
    "    def summarizeStrategy(self):\n",
    "        summaryPrompt = \"Résume la conversation suivante en gardant un maximum d'informations fournies par \" + self.userID + \" :\\n\"\n",
    "        lastMessage, lastMessageLength = self.history[-1]\n",
    "        history = \"\"\n",
    "        for m, l in self.history[:-1]:\n",
    "            history += m + \"\\n\"\n",
    "        summary = self.llm.invoke([HumanMessage(content=summaryPrompt + \"\\n\" + history)]).content\n",
    "        summaryLength = self.estimateLength(summary)\n",
    "        if summaryLength + lastMessageLength > self.memsize:\n",
    "            self.fifoStrategy()\n",
    "            return\n",
    "        self.history = [(summary, summaryLength), (lastMessage, lastMessageLength)]\n",
    "    \n",
    "    def fifoStrategy(self):\n",
    "        while self.historyLength() > self.memsize:\n",
    "            self.history = self.history[1:]\n",
    "\n",
    "    def historyLength(self):\n",
    "        return sum(length for _, length in self.history)\n",
    "\n",
    "    def estimateLength(self, text):\n",
    "        return self.llm.get_num_tokens(text)\n",
    "\n",
    "    def addToHistory(self, prompt):\n",
    "        self.history.append((prompt, self.estimateLength(prompt)))\n",
    "        if self.historyLength() > self.memsize:\n",
    "            self.summarizeStrategy()\n",
    "\n",
    "    def chat(self, prompt):\n",
    "        self.addToHistory(self.userID + \" \" + prompt)\n",
    "\n",
    "        recommendations = recommend_game(prompt)\n",
    "        games_list = \", \".join([game[0] for game in recommendations])\n",
    "\n",
    "        chat_prompt = f\"\"\"\n",
    "        L'utilisateur cherche un jeu correspondant à : \"{prompt}\".\n",
    "        Voici les jeux recommandés : {games_list}.\n",
    "        Formule une réponse naturelle et engageante.\n",
    "        \"\"\"\n",
    "\n",
    "        fullPrompt = 'Historique de conversation :\\n'\n",
    "        for msg, _ in self.history:\n",
    "            fullPrompt += msg + \"\\n\"\n",
    "\n",
    "        fullPrompt += \"\\n\" + chat_prompt\n",
    "\n",
    "        resp = self.llm.invoke([HumanMessage(content=fullPrompt)])\n",
    "        content = resp.content\n",
    "        if content.startswith(self.llmID + \": \"):\n",
    "            content = content[len(self.llmID + \": \"):]\n",
    "\n",
    "        self.addToHistory(self.llmID + \" \" + content)\n",
    "        return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8ca7bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " llm = ChatOpenAI(\n",
    "        openai_api_key=\"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\",\n",
    "        openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "        model_name=\"mistralai/mistral-small-3.1-24b-instruct:free\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d64b33c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONTEXT_LENGTH = 500  \n",
    "session = ChatSession(CONTEXT_LENGTH, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0242fe-e8fd-4a5d-b162-08ed1c52525f",
   "metadata": {},
   "source": [
    "### Use Of chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78cb85ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Welcome to the video game recommendation chatbot with memory!\n",
      "\n",
      " Ask me a question (e.g.: “I want an RPG with a good scenario”).\n",
      "\n",
      " Type “exit” to quit.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "👤 Vous :  I want a adventure game like naruto or call of duty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Bot : Salut ! Si tu cherches un jeu d'aventure au style similaire à Naruto ou Call of Duty, je te propose de jeter un œil à ces trois options :\n",
      "\n",
      "1. **Adventures of the Cat Leopold** : Bien que ce ne soit pas exactement Naruto, ce jeu offre une aventure pleine d'action et des combats intéressants. Tu devras explorer un vaste monde tout en accomplissant des missions captivantes.\n",
      "\n",
      "2. **Munlay Online** : Il combine des éléments de combat en équipe à la manière de Call of Duty, mais dans un environnement fantastique. C'est parfait pour ceux qui aiment des défis coopératifs et des combats stratégiques.\n",
      "\n",
      "3. **Piworld** : Il te plaira si tu cherches des aventures qui mélangent exploration et combat. C'est un jeu où chaque décision compte et où tu devras utiliser tes compétences pour progresser.\n",
      "\n",
      "Ces jeux offrent chacun une expérience unique qui, je l'espère, répondra à ton envie d'aventure et d'action ! Si tu as besoin de plus de recommandations ou de précisions, fais-le moi savoir !\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "👤 Vous :  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "À bientôt !\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Welcome to the video game recommendation chatbot with memory!\")\n",
    "print(\"\\n Ask me a question (e.g.: “I want an RPG with a good scenario”).\")\n",
    "print(\"\\n Type “exit” to quit.\\n\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"👤 Vous : \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"À bientôt !\")\n",
    "        break\n",
    "    \n",
    "    response = session.chat(user_input)\n",
    "    print(f\"🤖 Bot : {response}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
