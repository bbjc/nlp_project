{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T10:05:53.816579Z",
     "iopub.status.busy": "2025-02-11T10:05:53.816096Z",
     "iopub.status.idle": "2025-02-11T10:06:02.190700Z",
     "shell.execute_reply": "2025-02-11T10:06:02.189304Z",
     "shell.execute_reply.started": "2025-02-11T10:05:53.816540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.48.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.1.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.11.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.28.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (9.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (5.4.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2020.6.20)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T10:06:11.194883Z",
     "iopub.status.busy": "2025-02-11T10:06:11.194283Z",
     "iopub.status.idle": "2025-02-11T10:06:11.864684Z",
     "shell.execute_reply": "2025-02-11T10:06:11.863354Z",
     "shell.execute_reply.started": "2025-02-11T10:06:11.194838Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "words = [\"cat\",\"dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T10:06:14.037570Z",
     "iopub.status.busy": "2025-02-11T10:06:14.037115Z",
     "iopub.status.idle": "2025-02-11T10:06:16.728228Z",
     "shell.execute_reply": "2025-02-11T10:06:16.726780Z",
     "shell.execute_reply.started": "2025-02-11T10:06:14.037536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.6606],\n",
       "        [0.6606, 1.0000]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.encode(words)\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T10:06:21.366016Z",
     "iopub.status.busy": "2025-02-11T10:06:21.365458Z",
     "iopub.status.idle": "2025-02-11T10:06:28.877809Z",
     "shell.execute_reply": "2025-02-11T10:06:28.876357Z",
     "shell.execute_reply.started": "2025-02-11T10:06:21.365936Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.8.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.3)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.3)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\n",
      "Requirement already satisfied: wordcloud in /usr/local/lib/python3.11/dist-packages (1.9.4)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.48.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.1.1+cu121)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.28.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (9.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (5.4.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=0.25->seaborn) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25->seaborn) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2020.6.20)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install nltk scikit-learn numpy sentence-transformers matplotlib seaborn wordcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T10:06:35.062374Z",
     "iopub.status.busy": "2025-02-11T10:06:35.060811Z",
     "iopub.status.idle": "2025-02-11T10:06:35.069317Z",
     "shell.execute_reply": "2025-02-11T10:06:35.067608Z",
     "shell.execute_reply.started": "2025-02-11T10:06:35.062316Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_text_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = [line.strip() for line in f.readlines() if line.strip()]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T10:06:37.667802Z",
     "iopub.status.busy": "2025-02-11T10:06:37.667278Z",
     "iopub.status.idle": "2025-02-11T10:06:40.437835Z",
     "shell.execute_reply": "2025-02-11T10:06:40.436272Z",
     "shell.execute_reply.started": "2025-02-11T10:06:37.667761Z"
    }
   },
   "outputs": [],
   "source": [
    "prompts=load_text_file(\"/datasets/data/prompts.txt\")\n",
    "responses= load_text_file(\"/datasets/data/responses.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T10:06:42.339724Z",
     "iopub.status.busy": "2025-02-11T10:06:42.338293Z",
     "iopub.status.idle": "2025-02-11T10:06:44.023517Z",
     "shell.execute_reply": "2025-02-11T10:06:44.022037Z",
     "shell.execute_reply.started": "2025-02-11T10:06:42.339633Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def analyze_lengths(promptss, responsess):\n",
    "    lengths_prompts = [len(word_tokenize(p)) for p in promptss]\n",
    "    lengths_responses = [len(word_tokenize(r)) for r in responsess]\n",
    "    \n",
    "    min_idx = np.argmin(lengths_responses)\n",
    "    max_idx = np.argmax(lengths_responses)\n",
    "\n",
    "    print(f\"Réponse la plus courte ({lengths_responses[min_idx]} mots) : {responses[min_idx]}\")\n",
    "    print(f\"Réponse la plus longue ({lengths_responses[max_idx]} mots) : {responses[max_idx]}\")\n",
    "\n",
    "    ratios = [lr / lp if lp != 0 else 0 for lp, lr in zip(lengths_prompts, lengths_responses)]\n",
    "    \n",
    "    print(f\"Longueur moyenne des prompts : {np.mean(lengths_prompts):.2f} mots\")\n",
    "    print(f\"Longueur moyenne des réponses : {np.mean(lengths_responses):.2f} mots\")\n",
    "    print(f\"Ratio moyen réponse/prompt : {np.mean(ratios):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T10:06:52.810998Z",
     "iopub.status.busy": "2025-02-11T10:06:52.810031Z",
     "iopub.status.idle": "2025-02-11T10:06:52.949928Z",
     "shell.execute_reply": "2025-02-11T10:06:52.948983Z",
     "shell.execute_reply.started": "2025-02-11T10:06:52.810950Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T09:26:15.492401Z",
     "iopub.status.busy": "2025-02-11T09:26:15.491907Z",
     "iopub.status.idle": "2025-02-11T09:31:25.736394Z",
     "shell.execute_reply": "2025-02-11T09:31:25.734919Z",
     "shell.execute_reply.started": "2025-02-11T09:26:15.492361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse la plus courte (1 mots) : -Oman\n",
      "Réponse la plus longue (514 mots) : (321983, \"\"\"The night sky was a quilt of twinkling lights.  ;  The night sky was a canopy of diamond dust.  ;  The night sky was a tapestry of bright shining stars.  ;  The night sky was a sea of shimmering lights.  ;  The night sky was a velvet cloak of stars.  ;  The night sky was a carpet of glittering jewels.  ;   The night sky was a sky of diamond stars.  ;  The night sky was a sky of shining stars.  ;  The night sky was a bed of diamond stars.  ;  The night sky was a field of stars.  ;  The night sky was a blanket of stars.  ;  The night sky was a galaxy of sparkling stars.  ;  The night sky was a glittering blanket of stars.  ;  The night sky was a field of diamond stars.  ;  The night sky was a cloak of glowing stars.  ;  The night sky was a sky of sparkling stars.  ;  The night sky was a night of sparkling stars.  ;  The night sky was a million specks of starlight.  ;  The night sky was a sky of luminescent stars.  ;  The night sky was a sky of twinkling stars.  ;  The night sky was a blanket of stars.  ;  The night sky was a dream of stars.  ;  The night sky was an infinity of stars.  ;  The night sky was a night of diamond stars.  ;  The night sky was a night of star-filled bliss.  ;  The night sky was a night of sparkling diamonds.  ;  The night sky was a galaxy of shimmering stars.  ;  The night sky was a night of shining stars.  ;  The night sky was a star-studded sky.  ;  The night sky was a night of beautiful stars.  ;  The night sky was a celestial bed of stars.  ;  The night sky was a night of starlight.  ;  The night sky was a night of stunning starlight.  ;  The night sky was a glittering sky of stars.  ;  The night sky was a sky of glittering stars.  ;  The night sky was a night of shimmering stars.  ;  The night sky was a sky of stars.  ;  The night sky was a sky of resplendent stars.  ;  The night sky was a sky of luminous stars.  ;  The night sky was a starlit sky.  ;  The night sky was a shimmering sky of stars.  ;  The night sky was an ocean of stars.  ;  The night sky was a night of stardust.  ;  The night sky was a canvas of stars.  ;  The night sky was a sky of stars and wonder.  ;  The night sky was a night of heavenly stars.  ;  The night sky was a blanket of stars.\"\"\"),\n",
      "Longueur moyenne des prompts : 18.29 mots\n",
      "Longueur moyenne des réponses : 31.63 mots\n",
      "Ratio moyen réponse/prompt : 2.27\n"
     ]
    }
   ],
   "source": [
    "analyze_lengths(prompts, responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T10:07:07.550160Z",
     "iopub.status.busy": "2025-02-11T10:07:07.549083Z",
     "iopub.status.idle": "2025-02-11T10:07:07.555230Z",
     "shell.execute_reply": "2025-02-11T10:07:07.554166Z",
     "shell.execute_reply.started": "2025-02-11T10:07:07.550114Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W+', ' ', text)  # Supprime les caractères spéciaux\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T10:07:09.580043Z",
     "iopub.status.busy": "2025-02-11T10:07:09.578671Z",
     "iopub.status.idle": "2025-02-11T10:07:09.588362Z",
     "shell.execute_reply": "2025-02-11T10:07:09.587181Z",
     "shell.execute_reply.started": "2025-02-11T10:07:09.579983Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calcul du TF-IDF\n",
    "def compute_tfidf(prompts, responses):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    def remove_stopwords(text):\n",
    "        words = word_tokenize(text)\n",
    "        return ' '.join([word for word in words if word.lower() not in stop_words])\n",
    "    \n",
    "    clean_prompts = [remove_stopwords(clean_text(p)) for p in prompts]\n",
    "    clean_responses = [remove_stopwords(clean_text(r)) for r in responses]\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    all_texts = clean_prompts + clean_responses\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
    "\n",
    "    return tfidf_matrix, vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T10:07:12.093473Z",
     "iopub.status.busy": "2025-02-11T10:07:12.092659Z",
     "iopub.status.idle": "2025-02-11T10:07:12.103790Z",
     "shell.execute_reply": "2025-02-11T10:07:12.102971Z",
     "shell.execute_reply.started": "2025-02-11T10:07:12.093434Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T10:07:14.012424Z",
     "iopub.status.busy": "2025-02-11T10:07:14.011192Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Calcul de la similarité sémantique\n",
    "def compute_semantic_similarity(prompts, responses):\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')  # Petit modèle rapide et efficace\n",
    "    embeddings_prompts = model.encode(prompts, convert_to_tensor=True)\n",
    "    embeddings_responses = model.encode(responses, convert_to_tensor=True)\n",
    "\n",
    "    similarities = cosine_similarity(embeddings_prompts.cpu(), embeddings_responses.cpu())\n",
    "\n",
    "    max_sim_idx = np.argmax(np.diag(similarities))\n",
    "    min_sim_idx = np.argmin(np.diag(similarities))\n",
    "\n",
    "    print(f\"Meilleure correspondance prompt-réponse (sim = {similarities[max_sim_idx, max_sim_idx]:.2f}):\")\n",
    "    print(f\" Prompt: {prompts[max_sim_idx]}\")\n",
    "    print(f\"  Réponse: {responses[max_sim_idx]}\\n\")\n",
    "\n",
    "    print(f\"❌ Pire correspondance prompt-réponse (sim = {similarities[min_sim_idx, min_sim_idx]:.2f}):\")\n",
    "    print(f\"   🔴 Prompt: {prompts[min_sim_idx]}\")\n",
    "    print(f\"   🔴 Réponse: {responses[min_sim_idx]}\\n\")\n",
    "\n",
    "\n",
    "tfidf_matrix, vectorizer = compute_tfidf(prompts, responses)\n",
    "\n",
    "compute_semantic_similarity(prompts, responses)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
