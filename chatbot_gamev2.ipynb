{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e07e0b2c-1642-465b-b386-d86c76494dde",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Chatbot for game recommandation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "024b161a-d527-4956-8580-03cb6810bf18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.21-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.45 (from langchain)\n",
      "  Downloading langchain_core-0.3.48-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.7 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.7-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.18-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.21)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain) (5.4.1)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.45->langchain)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.45->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (4.9.0)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core<1.0.0,>=0.3.45->langchain)\n",
      "  Downloading typing_extensions-4.13.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (2020.6.20)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/lib/python3/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.2.0)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (2.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Downloading langchain-0.3.21-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.48-py3-none-any.whl (418 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m418.7/418.7 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.7-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.3.18-py3-none-any.whl (351 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m351.9/351.9 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading orjson-3.10.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading typing_extensions-4.13.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: zstandard, typing-extensions, tenacity, orjson, jsonpatch, h11, annotated-types, pydantic-core, httpcore, pydantic, httpx, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.9.0\n",
      "    Uninstalling typing_extensions-4.9.0:\n",
      "      Successfully uninstalled typing_extensions-4.9.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.14\n",
      "    Uninstalling pydantic-1.10.14:\n",
      "      Successfully uninstalled pydantic-1.10.14\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "deepspeed 0.10.3 requires pydantic<2.0.0, but you have pydantic 2.10.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed annotated-types-0.7.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jsonpatch-1.33 langchain-0.3.21 langchain-core-0.3.48 langchain-text-splitters-0.3.7 langsmith-0.3.18 orjson-3.10.16 pydantic-2.10.6 pydantic-core-2.27.2 tenacity-9.0.0 typing-extensions-4.13.0 zstandard-0.23.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting langchain_openai\n",
      "  Downloading langchain_openai-0.3.10-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.48 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.3.48)\n",
      "Collecting openai<2.0.0,>=1.68.2 (from langchain_openai)\n",
      "  Downloading openai-1.68.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (0.3.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (5.4.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (4.13.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (2.10.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.68.2->langchain_openai)\n",
      "  Downloading jiter-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.66.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain_openai) (3.3)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.48->langchain_openai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.48->langchain_openai) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.48->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.48->langchain_openai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.48->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.48->langchain_openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.7)\n",
      "Downloading langchain_openai-0.3.10-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.68.2-py3-none-any.whl (606 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m606.1/606.1 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (351 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m351.8/351.8 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jiter, tiktoken, openai, langchain_openai\n",
      "Successfully installed jiter-0.9.0 langchain_openai-0.3.10 openai-1.68.2 tiktoken-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96887d09-f8e9-484a-be59-d83a21002a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: openai 1.68.2\n",
      "Uninstalling openai-1.68.2:\n",
      "  Successfully uninstalled openai-1.68.2\n",
      "Found existing installation: langchain 0.3.21\n",
      "Uninstalling langchain-0.3.21:\n",
      "  Successfully uninstalled langchain-0.3.21\n",
      "Found existing installation: langchain-openai 0.3.10\n",
      "Uninstalling langchain-openai-0.3.10:\n",
      "  Successfully uninstalled langchain-openai-0.3.10\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting openai\n",
      "  Using cached openai-1.68.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.3.21-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain_openai\n",
      "  Using cached langchain_openai-0.3.10-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.48)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.18)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.21)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain) (5.4.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->openai) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/lib/python3/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (2.4)\n",
      "Using cached openai-1.68.2-py3-none-any.whl (606 kB)\n",
      "Using cached langchain-0.3.21-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_openai-0.3.10-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: openai, langchain_openai, langchain\n",
      "Successfully installed langchain-0.3.21 langchain_openai-0.3.10 openai-1.68.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall openai langchain langchain_openai -y\n",
    "!pip install openai langchain langchain_openai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3ff55db-13e7-4045-b701-e475b6aab091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip show typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c617d1eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7711c08f-b513-4618-8bd6-fd6cb0c5db23",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ddd0d5-59b7-40ed-b613-407973ef75b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2', cache_folder=\"./cache\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7733c8dd-57bf-4798-9fec-0f2f9d7041a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Charger les jeux IGDB\n",
    "#with open(\"igdb_games.json\", \"r\") as f:\n",
    "    #games_data = json.load(f)\n",
    "\n",
    "#for game in games_data:\n",
    " #   game[\"embedding\"] = embedding_model.encode(game.get(\"summary\", \"No description\")).tolist()  \n",
    "\n",
    "# Sauvegarde en JSON\n",
    "#with open(\"igdb_games_embedding.json\", \"w\") as f:\n",
    "   # json.dump(games_data, f, indent=4)  \n",
    "\n",
    "#print(\"Base de donnÃ©es des jeux enregistrÃ©e avec embeddings !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73946ad8-26e0-45f4-bb06-b5c418728006",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08f1bbae-916f-4480-bdcb-0081b870808b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load steam reviews\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "steam_reviews = pd.read_csv(\"./steam_reviews.csv\", names=['id', 'app_id', 'content', 'author_id', 'sentiment'], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d04b84c1-6d9b-47a6-847a-2c51a8364d2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>At least its a counter strike</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uh    So far my playthrough has not been great...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Better mechanics than cs</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>buggy mess and NOT fun to play at all</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Whoever came up with this  is gonna fucking ge...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content sentiment\n",
       "0               At least its a counter strike         negative\n",
       "1  Uh    So far my playthrough has not been great...  negative\n",
       "2                          Better mechanics than cs   negative\n",
       "3              buggy mess and NOT fun to play at all  negative\n",
       "4  Whoever came up with this  is gonna fucking ge...  negative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the reviews\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    # remove html tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # remove @mentions\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text)\n",
    "\n",
    "    # remove urls\n",
    "    text = re.sub(r'https?://[A-Za-z0-9./]+', '', text)\n",
    "\n",
    "    # keep only alphanumeric characters\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "def remove_special_chars(tokens):\n",
    "    return [word for word in tokens if word.isalnum()]\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(tokens):\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "def preprocess(tokens):\n",
    "    # return lemmatize(remove_special_chars(remove_stopwords(tokens)))\n",
    "    return lemmatize(remove_special_chars(tokens))\n",
    "\n",
    "steam_reviews = steam_reviews[['content', 'sentiment']]\n",
    "steam_reviews['content'] = steam_reviews['content'].apply(clean_text)\n",
    "steam_reviews['sentiment'] = steam_reviews['sentiment'].apply(lambda x: str(x).lower())\n",
    "steam_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98be907f-2f0d-461e-b21d-9a9b25cda075",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201151, 97755)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use tfidf to vectorize the reviews\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df = steam_reviews\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=None, \n",
    "                        lowercase=False,\n",
    "                        preprocessor=None)\n",
    "\n",
    "X = tfidf.fit_transform(df['content'])\n",
    "X.shape # (n_samples, n_features) = (201151, 97755)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "111d629d-eda1-4a32-a2de-d0d1a18ff441",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8405981546293351"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the logistic regression model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y = df['sentiment'] # target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr.fit(X_train,y_train) # fit the model\n",
    "preds = lr.predict(X_test) # make predictions\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(preds,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71633586-4b62-4fb5-bd0b-a787da751326",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('positive', 0.9506846551103045)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the sentiment of a review\n",
    "def predict_sentiment(review):\n",
    "    review = clean_text(review)\n",
    "    review = tfidf.transform([review])\n",
    "    sentiment = lr.predict(review)[0]\n",
    "    proba = lr.predict_proba(review)[0][0 if sentiment == 'negative' else 1]\n",
    "    return sentiment, proba\n",
    "\n",
    "predict_sentiment(\"I love game about war\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67d318b-2df3-4b84-942e-1281aa37032f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73f33dbc-a25c-4d29-850f-838ef5ca1e16",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m2025-03-26 08:26:48.007187: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-26 08:26:48.007267: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-26 08:26:48.008896: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-26 08:26:48.017417: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-26 08:26:49.240573: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-03-26 08:26:50.652775: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-26 08:26:50.653276: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-26 08:26:50.653450: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "Collecting en-core-web-md==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.6.0/en_core_web_md-3.6.0-py3-none-any.whl (42.8 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from en-core-web-md==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.11.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.26.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (69.0.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.11/dist-packages (from pathy>=0.10.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2020.6.20)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.11/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.1.4)\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy\n",
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56fd4d63-cc2c-4d91-93cc-adbdb4813f60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "#python -m spacy download en_core_web_md\n",
    "from fuzzywuzzy import process  # Pour la recherche approximative\n",
    "import random as random\n",
    "# Charger le fichier JSON\n",
    "with open(\"igdb_games_embedding.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    games_data = json.load(file)\n",
    "    \n",
    "sample_games = random.sample(games_data, 1000)\n",
    "\n",
    "# Initialiser les listes\n",
    "games_db = []\n",
    "categories_db = set()  # Utiliser un set pour Ã©viter les doublons\n",
    "\n",
    "# Parcourir les jeux dans le JSON\n",
    "for game in sample_games:\n",
    "    if \"name\" in game:\n",
    "        games_db.append(game[\"name\"])  # Ajouter le nom du jeu\n",
    "    \n",
    "    if \"genres\" in game and isinstance(game[\"genres\"], list):\n",
    "        for genre in game[\"genres\"]:\n",
    "            if \"name\" in genre:  # VÃ©rifier si le nom du genre existe\n",
    "                categories_db.add(genre[\"name\"])\n",
    "\n",
    "# Convertir en liste finale\n",
    "categories_db = list(categories_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d220825b-d85a-4f71-a368-7379e3cc3060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Afficher le rÃ©sultat\n",
    "#print(\"Jeux dÃ©tectÃ©s:\", games_db[:10])\n",
    "#print(\"CatÃ©gories dÃ©tectÃ©es:\", categories_db[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2286e0ad-4670-4fc8-9c21-750697a05cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Charger le modÃ¨le spaCy\n",
    "nlp = spacy.load(\"en_core_web_md\")  # ou \"fr_core_news_md\" pour le franÃ§ais\n",
    "\n",
    "# Initialisation du PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
    "\n",
    "game_to_use=games_db\n",
    "# Ajouter les noms de jeux et catÃ©gories au matcher\n",
    "patterns_games = [nlp(game) for game in game_to_use]\n",
    "patterns_categories = [nlp(cat) for cat in categories_db]\n",
    "\n",
    "matcher.add(\"GAME\", patterns_games)\n",
    "matcher.add(\"CATEGORY\", patterns_categories)\n",
    "\n",
    "def fuzzy_match_game(text, threshold=80):\n",
    "    \"\"\"\n",
    "    Recherche un jeu dans la base avec tolÃ©rance aux fautes de frappe.\n",
    "    Renvoie le jeu correspondant si la similaritÃ© est supÃ©rieure au seuil.\n",
    "    \"\"\"\n",
    "    best_match, score = process.extractOne(text, game_to_use) if text else (None, 0)\n",
    "    return best_match if score >= threshold else None\n",
    "\n",
    "def extract_games_and_categories(text):\n",
    "    \"\"\"\n",
    "    DÃ©tecte les jeux et catÃ©gories dans un texte en combinant PhraseMatcher et fuzzy matching.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)  # Tokenisation\n",
    "    matches = matcher(doc)  # Recherche des correspondances exactes\n",
    "    \n",
    "    extracted_info = {\"games\": set(), \"categories\": set()}\n",
    "    matched_texts = set()  # Pour Ã©viter les doublons\n",
    "\n",
    "    # Recherche des jeux et catÃ©gories exacts avec PhraseMatcher\n",
    "    for match_id, start, end in matches:\n",
    "        label = nlp.vocab.strings[match_id]\n",
    "        entity = doc[start:end].text\n",
    "        \n",
    "        if label == \"GAME\":\n",
    "            extracted_info[\"games\"].add(entity)\n",
    "        elif label == \"CATEGORY\":\n",
    "            extracted_info[\"categories\"].add(entity)\n",
    "        \n",
    "        matched_texts.add(entity.lower())\n",
    "\n",
    "    # ğŸ” Recherche des jeux approximatifs avec filtre\n",
    "    for token in doc:\n",
    "        if (token.text.lower() not in matched_texts  # Ã‰viter les doublons\n",
    "            and not token.is_punct  # Ignorer la ponctuation\n",
    "            and not token.is_stop  # Ignorer les mots vides (\"le\", \"et\", \"de\", etc.)\n",
    "            and len(token.text) > 2):  # Ignorer les mots trop courts\n",
    "        \n",
    "            fuzzy_game = fuzzy_match_game(token.text)\n",
    "            if fuzzy_game:\n",
    "                extracted_info[\"games\"].add(fuzzy_game)\n",
    "    \n",
    "    return extracted_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea7cc2ed-01fb-4c46-a0bd-44bfa5fd92be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#text = \"J'adore Elden Ring, c'est un excellent RPG. Je cherche un jeu d'action qui ressemble Ã  Hades. J'ai aussi aimÃ© Dark Sols.\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#result = extract_games_and_categories(text)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresult\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "#text = \"J'adore Elden Ring, c'est un excellent RPG. Je cherche un jeu d'action qui ressemble Ã  Hades. J'ai aussi aimÃ© Dark Sols.\"\n",
    "\n",
    "#result = extract_games_and_categories(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e50697d-2c6f-436a-ada6-d3a3d3de8719",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Function for recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae245b6a-eee6-4a84-a1e2-f9573568eb73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "import random\n",
    "\n",
    "# Fonction de recommandation basÃ©e sur la similaritÃ©\n",
    "def recommend_game(user_query):\n",
    "    #extract infos\n",
    "    extract = extract_games_and_categories(user_query)\n",
    "    # RÃ©cupÃ©rer les descriptions des jeux extraits\n",
    "    game_descriptions = {}\n",
    "    for game_name in extract['games']:\n",
    "        for game in sample_games:\n",
    "            if game['name'] == game_name:\n",
    "                game_descriptions[game_name] = \"I want an adventure game\"\n",
    "\n",
    "\n",
    "    # Sentiment analysis\n",
    "    sentiment, proba = predict_sentiment(user_query)\n",
    "\n",
    "    recommand_similar_game = True # default\n",
    "    if sentiment=='negative' and proba > 0.70:\n",
    "        recommand_similar_game = False\n",
    "        \n",
    "    if game_descriptions:\n",
    "        description_query = \" \".join(game_descriptions.values())  # Combine toutes les descriptions\n",
    "        user_query = description_query\n",
    "    query_embedding = embedding_model.encode(user_query)\n",
    "    similarities = [\n",
    "        (game[\"name\"], 1 - cosine(query_embedding, game[\"embedding\"]), game.get(\"rating\", 0))\n",
    "        for game in sample_games if \"embedding\" in game\n",
    "    ]\n",
    "\n",
    "    if recommand_similar_game:\n",
    "        similarities.sort(key=lambda x:(x[1], x[2]), reverse=True)\n",
    "    else:\n",
    "        similarities.sort(key=lambda x: (x[1], x[2]), reverse=False)\n",
    "\n",
    "    return similarities[:3]\n",
    "\n",
    "# Test\n",
    "#user_input = \"I don't love war game\"\n",
    "#print(\"Jeux recommandÃ©s :\", recommend_game(user_input))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1f1bd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5eb0cbd-dfea-422b-8365-c8bbf5d9742d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChatSession:\n",
    "    def __init__(self, memsize, llm):\n",
    "        self.llm = llm\n",
    "        self.memsize = memsize\n",
    "        self.history = []\n",
    "        self.llmID = \"ASSISTANT:\"\n",
    "        self.userID = \"USER:\"\n",
    "                \n",
    "    def summarizeStrategy(self):\n",
    "        summaryPrompt = \"RÃ©sume la conversation suivante en gardant un maximum d'informations fournies par \" + self.userID + \" :\\n\"\n",
    "        lastMessage, lastMessageLength = self.history[-1]\n",
    "        history = \"\"\n",
    "        for m, l in self.history[:-1]:\n",
    "            history += m + \"\\n\"\n",
    "        summary = self.llm.invoke([HumanMessage(content=summaryPrompt + \"\\n\" + history)]).content\n",
    "        summaryLength = self.estimateLength(summary)\n",
    "        if summaryLength + lastMessageLength > self.memsize:\n",
    "            self.fifoStrategy()\n",
    "            return\n",
    "        self.history = [(summary, summaryLength), (lastMessage, lastMessageLength)]\n",
    "    \n",
    "    def fifoStrategy(self):\n",
    "        while self.historyLength() > self.memsize:\n",
    "            self.history = self.history[1:]\n",
    "\n",
    "    def historyLength(self):\n",
    "        return sum(length for _, length in self.history)\n",
    "\n",
    "    def estimateLength(self, text):\n",
    "        return self.llm.get_num_tokens(text)\n",
    "\n",
    "    def addToHistory(self, prompt):\n",
    "        self.history.append((prompt, self.estimateLength(prompt)))\n",
    "        if self.historyLength() > self.memsize:\n",
    "            self.summarizeStrategy()\n",
    "\n",
    "    def chat(self, prompt):\n",
    "        self.addToHistory(self.userID + \" \" + prompt)\n",
    "\n",
    "        recommendations = recommend_game(prompt)\n",
    "        games_list = \", \".join([game[0] for game in recommendations])\n",
    "\n",
    "        chat_prompt = f\"\"\"\n",
    "        L'utilisateur cherche un jeu correspondant Ã  : \"{prompt}\".\n",
    "        Voici les jeux recommandÃ©s : {games_list}.\n",
    "        Formule une rÃ©ponse naturelle et engageante.\n",
    "        \"\"\"\n",
    "\n",
    "        fullPrompt = 'Historique de conversation :\\n'\n",
    "        for msg, _ in self.history:\n",
    "            fullPrompt += msg + \"\\n\"\n",
    "\n",
    "        fullPrompt += \"\\n\" + chat_prompt\n",
    "\n",
    "        resp = self.llm.invoke([HumanMessage(content=fullPrompt)])\n",
    "        content = resp.content\n",
    "        if content.startswith(self.llmID + \": \"):\n",
    "            content = content[len(self.llmID + \": \"):]\n",
    "\n",
    "        self.addToHistory(self.llmID + \" \" + content)\n",
    "        return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8ca7bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " llm = ChatOpenAI(\n",
    "        openai_api_key=\"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\",\n",
    "        openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "        model_name=\"mistralai/mistral-small-3.1-24b-instruct:free\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d64b33c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONTEXT_LENGTH = 500  \n",
    "session = ChatSession(CONTEXT_LENGTH, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0242fe-e8fd-4a5d-b162-08ed1c52525f",
   "metadata": {},
   "source": [
    "### Use Of chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78cb85ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Welcome to the video game recommendation chatbot with memory!\n",
      "\n",
      " Ask me a question (e.g.: â€œI want an RPG with a good scenarioâ€).\n",
      "\n",
      " Type â€œexitâ€ to quit.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ‘¤ Vous :  i want to have an adventure game\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Bot : Bien sÃ»r ! Voici quelques suggestions qui devraient te plaire si tu cherches un jeu d'aventure :\n",
      "\n",
      "1. **The Unlikely Prometheus** : C'est un jeu indÃ©pendant avec une histoire captivante et des mÃ©caniques de gameplay intÃ©ressantes. Parfait pour les amateurs de mystÃ¨res et de dÃ©couvertes.\n",
      "\n",
      "2. **NetGame Adventure** : Si tu aimes les jeux en ligne avec une communautÃ© active, celui-ci pourrait Ãªtre fait pour toi. Il offre une expÃ©rience d'aventure en rÃ©seau, plein de dÃ©fis et de surprises.\n",
      "\n",
      "3. **Trance** : Pour ceux qui cherchent une expÃ©rience immersive et psychÃ©dÃ©lique, Trance est un excellent choix. Ce jeu explore des thÃ¨mes de rÃ©alitÃ© augmentÃ©e et de mystÃ¨re, tout en t'offrant des combats et des puzzles stimulants.\n",
      "\n",
      "Chacun de ces jeux a son propre style unique, donc tu devrais trouver quelque chose qui te convient parfaitement. Bonne aventure ! ğŸ®âœ¨\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ‘¤ Vous :  i want to have a killer game\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Bot : D'accord, si tu veux un jeu qui soit vÃ©ritablement captivant et intense, voici quelques options parmi celles mentionnÃ©es qui pourraient te plaire :\n",
      "\n",
      "1. **The Unlikely Prometheus** : Ce jeu est parfait si tu aimes les histoires riches en mystÃ¨re et en rebondissements. C'est un vÃ©ritablequÃªte pleine de dÃ©fis et de surprises qui te tiendra en haleine du dÃ©but Ã  la fin.\n",
      "\n",
      "2. **NetGame Adventure** : Pour les amateurs de compÃ©tition et d'interaction en ligne, c'est le jeu idÃ©al. Avec une communautÃ© active, tu seras sÃ»r de trouver des adversaires redoutables et des dÃ©fis stimulants.\n",
      "\n",
      "3. **Trance** : Ce jeu est parfait si tu cherches une expÃ©rience vraiment immersive et intense. Avec ses thÃ¨mes de rÃ©alitÃ© augmentÃ©e et ses puzzles complexes, Trance promet une aventure captivante et psychÃ©dÃ©lique.\n",
      "\n",
      "Chacun de ces jeux a des Ã©lÃ©ments qui peuvent rendre ton expÃ©rience de jeu vraiment \"killer\". J'espÃ¨re que tu trouveras celui qui correspond le mieux Ã  tes attentes ! Bonne aventure et amuse-toi bien ! ğŸ®ğŸ”¥\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ‘¤ Vous :  I want to have an adventure game. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Bot : Super ! Si tu cherches un jeu d'aventure, tu as de superbes options Ã  considÃ©rer. Chacun de ces jeux a ses propres atouts et peut te plonger dans des univers diffÃ©rents, voici un rappel :\n",
      "\n",
      "1. **The Unlikely Prometheus** : Parfait pour ceux qui aiment les mystÃ¨res et les dÃ©couvertes. C'est une expÃ©rience indÃ©pendante avec une histoire captivante et des mÃ©caniques de gameplay intÃ©ressantes.\n",
      "\n",
      "2. **NetGame Adventure** : IdÃ©al si tu prÃ©fÃ¨res les expÃ©riences en ligne et interactives. Avec une communautÃ© active, tu pourras relever des dÃ©fis et t'immerger dans une aventure collaborative pleine de surprises.\n",
      "\n",
      "3. **Trance** : Pour une expÃ©rience vraiment immersive et psychÃ©dÃ©lique, ce jeu explore des thÃ¨mes de rÃ©alitÃ© augmentÃ©e avec des puzzles et des combats stimulants. C'est une vÃ©ritable plongÃ©e dans l'inconnu!\n",
      "\n",
      "Chacun de ces jeux t'offrira une aventure inoubliable selon tes prÃ©fÃ©rences. Bonne aventure et amuse-toi bien avec celui que tu choisiras! ğŸ®âœ¨\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ‘¤ Vous :  I like cars and I want a game with\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Bot : D'accord, j'ai notÃ© que tu aimes les voitures et que tu cherches un jeu en rapport avec Ã§a. Malheureusement, les jeux que j'ai mentionnÃ©s avant ne sont pas spÃ©cifiquement axÃ©s sur les voitures. Mais je peux te suggÃ©rer quelques alternatives qui pourraient bien te plaire :\n",
      "\n",
      "1. **Forza Horizon 5** : Ce jeu te permet de conduire dans des environnements magnifiques et de participer Ã  des courses Ã©poustouflantes. C'est parfait pour les amateurs de voitures et d'aventure.\n",
      "\n",
      "2. **Gran Turismo Sport** : Si tu prÃ©fÃ¨res quelque chose de plus rÃ©aliste, ce jeu offre une expÃ©rience de conduite trÃ¨s immersion avec des graphismes incroyables et des courses compÃ©titives.\n",
      "\n",
      "3. **Need for Speed Heat** : Pour une aventure plus arcade et des dÃ©fis palpitants, ce jeu te propose des courses nocturnes illÃ©gales et des poursuites avec la police.\n",
      "\n",
      "Chacun de ces jeux tiendra compte de ta passion pour les voitures et te proposera une aventure unique et passionnante. Bonne route et amuse-toi bien ! ğŸï¸ğŸ®\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ‘¤ Vous :  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã€ bientÃ´t !\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Welcome to the video game recommendation chatbot with memory!\")\n",
    "print(\"\\n Ask me a question (e.g.: â€œI want an RPG with a good scenarioâ€).\")\n",
    "print(\"\\n Type â€œexitâ€ to quit.\\n\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"ğŸ‘¤ Vous : \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"Ã€ bientÃ´t !\")\n",
    "        break\n",
    "    \n",
    "    response = session.chat(user_input)\n",
    "    print(f\"ğŸ¤– Bot : {response}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
