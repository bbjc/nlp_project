{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e07e0b2c-1642-465b-b386-d86c76494dde",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Chatbot for game recommandation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "024b161a-d527-4956-8580-03cb6810bf18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.21-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.45 (from langchain)\n",
      "  Downloading langchain_core-0.3.48-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.7 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.7-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.18-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.21)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain) (5.4.1)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.45->langchain)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.45->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (4.9.0)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core<1.0.0,>=0.3.45->langchain)\n",
      "  Downloading typing_extensions-4.13.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (2020.6.20)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/lib/python3/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.2.0)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (2.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Downloading langchain-0.3.21-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.48-py3-none-any.whl (418 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m418.7/418.7 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.7-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.3.18-py3-none-any.whl (351 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m351.9/351.9 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading orjson-3.10.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading typing_extensions-4.13.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: zstandard, typing-extensions, tenacity, orjson, jsonpatch, h11, annotated-types, pydantic-core, httpcore, pydantic, httpx, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.9.0\n",
      "    Uninstalling typing_extensions-4.9.0:\n",
      "      Successfully uninstalled typing_extensions-4.9.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.14\n",
      "    Uninstalling pydantic-1.10.14:\n",
      "      Successfully uninstalled pydantic-1.10.14\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "deepspeed 0.10.3 requires pydantic<2.0.0, but you have pydantic 2.10.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed annotated-types-0.7.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jsonpatch-1.33 langchain-0.3.21 langchain-core-0.3.48 langchain-text-splitters-0.3.7 langsmith-0.3.18 orjson-3.10.16 pydantic-2.10.6 pydantic-core-2.27.2 tenacity-9.0.0 typing-extensions-4.13.0 zstandard-0.23.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting langchain_openai\n",
      "  Downloading langchain_openai-0.3.10-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.48 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.3.48)\n",
      "Collecting openai<2.0.0,>=1.68.2 (from langchain_openai)\n",
      "  Downloading openai-1.68.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (0.3.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (5.4.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (4.13.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.48->langchain_openai) (2.10.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.68.2->langchain_openai)\n",
      "  Downloading jiter-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.66.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain_openai) (3.3)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.48->langchain_openai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.48->langchain_openai) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.48->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.48->langchain_openai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.48->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.48->langchain_openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.7)\n",
      "Downloading langchain_openai-0.3.10-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.68.2-py3-none-any.whl (606 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m606.1/606.1 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (351 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m351.8/351.8 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jiter, tiktoken, openai, langchain_openai\n",
      "Successfully installed jiter-0.9.0 langchain_openai-0.3.10 openai-1.68.2 tiktoken-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96887d09-f8e9-484a-be59-d83a21002a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: openai 1.68.2\n",
      "Uninstalling openai-1.68.2:\n",
      "  Successfully uninstalled openai-1.68.2\n",
      "Found existing installation: langchain 0.3.21\n",
      "Uninstalling langchain-0.3.21:\n",
      "  Successfully uninstalled langchain-0.3.21\n",
      "Found existing installation: langchain-openai 0.3.10\n",
      "Uninstalling langchain-openai-0.3.10:\n",
      "  Successfully uninstalled langchain-openai-0.3.10\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting openai\n",
      "  Using cached openai-1.68.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.3.21-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain_openai\n",
      "  Using cached langchain_openai-0.3.10-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.48)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.18)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.21)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain) (5.4.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->openai) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/lib/python3/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (2.4)\n",
      "Using cached openai-1.68.2-py3-none-any.whl (606 kB)\n",
      "Using cached langchain-0.3.21-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_openai-0.3.10-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: openai, langchain_openai, langchain\n",
      "Successfully installed langchain-0.3.21 langchain_openai-0.3.10 openai-1.68.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall openai langchain langchain_openai -y\n",
    "!pip install openai langchain langchain_openai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3ff55db-13e7-4045-b701-e475b6aab091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip show typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c617d1eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7711c08f-b513-4618-8bd6-fd6cb0c5db23",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ddd0d5-59b7-40ed-b613-407973ef75b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2', cache_folder=\"./cache\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7733c8dd-57bf-4798-9fec-0f2f9d7041a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Charger les jeux IGDB\n",
    "#with open(\"igdb_games.json\", \"r\") as f:\n",
    "    #games_data = json.load(f)\n",
    "\n",
    "#for game in games_data:\n",
    " #   game[\"embedding\"] = embedding_model.encode(game.get(\"summary\", \"No description\")).tolist()  \n",
    "\n",
    "# Sauvegarde en JSON\n",
    "#with open(\"igdb_games_embedding.json\", \"w\") as f:\n",
    "   # json.dump(games_data, f, indent=4)  \n",
    "\n",
    "#print(\"Base de données des jeux enregistrée avec embeddings !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73946ad8-26e0-45f4-bb06-b5c418728006",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08f1bbae-916f-4480-bdcb-0081b870808b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load steam reviews\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "steam_reviews = pd.read_csv(\"./steam_reviews.csv\", names=['id', 'app_id', 'content', 'author_id', 'sentiment'], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d04b84c1-6d9b-47a6-847a-2c51a8364d2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>At least its a counter strike</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uh    So far my playthrough has not been great...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Better mechanics than cs</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>buggy mess and NOT fun to play at all</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Whoever came up with this  is gonna fucking ge...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content sentiment\n",
       "0               At least its a counter strike         negative\n",
       "1  Uh    So far my playthrough has not been great...  negative\n",
       "2                          Better mechanics than cs   negative\n",
       "3              buggy mess and NOT fun to play at all  negative\n",
       "4  Whoever came up with this  is gonna fucking ge...  negative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the reviews\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    # remove html tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # remove @mentions\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text)\n",
    "\n",
    "    # remove urls\n",
    "    text = re.sub(r'https?://[A-Za-z0-9./]+', '', text)\n",
    "\n",
    "    # keep only alphanumeric characters\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "def remove_special_chars(tokens):\n",
    "    return [word for word in tokens if word.isalnum()]\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(tokens):\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "def preprocess(tokens):\n",
    "    # return lemmatize(remove_special_chars(remove_stopwords(tokens)))\n",
    "    return lemmatize(remove_special_chars(tokens))\n",
    "\n",
    "steam_reviews = steam_reviews[['content', 'sentiment']]\n",
    "steam_reviews['content'] = steam_reviews['content'].apply(clean_text)\n",
    "steam_reviews['sentiment'] = steam_reviews['sentiment'].apply(lambda x: str(x).lower())\n",
    "steam_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98be907f-2f0d-461e-b21d-9a9b25cda075",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201151, 97755)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use tfidf to vectorize the reviews\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df = steam_reviews\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=None, \n",
    "                        lowercase=False,\n",
    "                        preprocessor=None)\n",
    "\n",
    "X = tfidf.fit_transform(df['content'])\n",
    "X.shape # (n_samples, n_features) = (201151, 97755)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "111d629d-eda1-4a32-a2de-d0d1a18ff441",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8405981546293351"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the logistic regression model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y = df['sentiment'] # target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr.fit(X_train,y_train) # fit the model\n",
    "preds = lr.predict(X_test) # make predictions\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(preds,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71633586-4b62-4fb5-bd0b-a787da751326",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('positive', 0.9506846551103045)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the sentiment of a review\n",
    "def predict_sentiment(review):\n",
    "    review = clean_text(review)\n",
    "    review = tfidf.transform([review])\n",
    "    sentiment = lr.predict(review)[0]\n",
    "    proba = lr.predict_proba(review)[0][0 if sentiment == 'negative' else 1]\n",
    "    return sentiment, proba\n",
    "\n",
    "predict_sentiment(\"I love game about war\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67d318b-2df3-4b84-942e-1281aa37032f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73f33dbc-a25c-4d29-850f-838ef5ca1e16",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m2025-03-26 08:26:48.007187: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-26 08:26:48.007267: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-26 08:26:48.008896: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-26 08:26:48.017417: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-26 08:26:49.240573: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-03-26 08:26:50.652775: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-26 08:26:50.653276: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-26 08:26:50.653450: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "Collecting en-core-web-md==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.6.0/en_core_web_md-3.6.0-py3-none-any.whl (42.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from en-core-web-md==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.11.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.26.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (69.0.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.11/dist-packages (from pathy>=0.10.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2020.6.20)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.11/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.1.4)\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy\n",
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56fd4d63-cc2c-4d91-93cc-adbdb4813f60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "#python -m spacy download en_core_web_md\n",
    "from fuzzywuzzy import process  # Pour la recherche approximative\n",
    "import random as random\n",
    "# Charger le fichier JSON\n",
    "with open(\"igdb_games_embedding.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    games_data = json.load(file)\n",
    "    \n",
    "sample_games = random.sample(games_data, 1000)\n",
    "\n",
    "# Initialiser les listes\n",
    "games_db = []\n",
    "categories_db = set()  # Utiliser un set pour éviter les doublons\n",
    "\n",
    "# Parcourir les jeux dans le JSON\n",
    "for game in sample_games:\n",
    "    if \"name\" in game:\n",
    "        games_db.append(game[\"name\"])  # Ajouter le nom du jeu\n",
    "    \n",
    "    if \"genres\" in game and isinstance(game[\"genres\"], list):\n",
    "        for genre in game[\"genres\"]:\n",
    "            if \"name\" in genre:  # Vérifier si le nom du genre existe\n",
    "                categories_db.add(genre[\"name\"])\n",
    "\n",
    "# Convertir en liste finale\n",
    "categories_db = list(categories_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d220825b-d85a-4f71-a368-7379e3cc3060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Afficher le résultat\n",
    "#print(\"Jeux détectés:\", games_db[:10])\n",
    "#print(\"Catégories détectées:\", categories_db[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2286e0ad-4670-4fc8-9c21-750697a05cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Charger le modèle spaCy\n",
    "nlp = spacy.load(\"en_core_web_md\")  # ou \"fr_core_news_md\" pour le français\n",
    "\n",
    "# Initialisation du PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
    "\n",
    "game_to_use=games_db\n",
    "# Ajouter les noms de jeux et catégories au matcher\n",
    "patterns_games = [nlp(game) for game in game_to_use]\n",
    "patterns_categories = [nlp(cat) for cat in categories_db]\n",
    "\n",
    "matcher.add(\"GAME\", patterns_games)\n",
    "matcher.add(\"CATEGORY\", patterns_categories)\n",
    "\n",
    "def fuzzy_match_game(text, threshold=80):\n",
    "    \"\"\"\n",
    "    Recherche un jeu dans la base avec tolérance aux fautes de frappe.\n",
    "    Renvoie le jeu correspondant si la similarité est supérieure au seuil.\n",
    "    \"\"\"\n",
    "    best_match, score = process.extractOne(text, game_to_use) if text else (None, 0)\n",
    "    return best_match if score >= threshold else None\n",
    "\n",
    "def extract_games_and_categories(text):\n",
    "    \"\"\"\n",
    "    Détecte les jeux et catégories dans un texte en combinant PhraseMatcher et fuzzy matching.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)  # Tokenisation\n",
    "    matches = matcher(doc)  # Recherche des correspondances exactes\n",
    "    \n",
    "    extracted_info = {\"games\": set(), \"categories\": set()}\n",
    "    matched_texts = set()  # Pour éviter les doublons\n",
    "\n",
    "    # Recherche des jeux et catégories exacts avec PhraseMatcher\n",
    "    for match_id, start, end in matches:\n",
    "        label = nlp.vocab.strings[match_id]\n",
    "        entity = doc[start:end].text\n",
    "        \n",
    "        if label == \"GAME\":\n",
    "            extracted_info[\"games\"].add(entity)\n",
    "        elif label == \"CATEGORY\":\n",
    "            extracted_info[\"categories\"].add(entity)\n",
    "        \n",
    "        matched_texts.add(entity.lower())\n",
    "\n",
    "    # 🔍 Recherche des jeux approximatifs avec filtre\n",
    "    for token in doc:\n",
    "        if (token.text.lower() not in matched_texts  # Éviter les doublons\n",
    "            and not token.is_punct  # Ignorer la ponctuation\n",
    "            and not token.is_stop  # Ignorer les mots vides (\"le\", \"et\", \"de\", etc.)\n",
    "            and len(token.text) > 2):  # Ignorer les mots trop courts\n",
    "        \n",
    "            fuzzy_game = fuzzy_match_game(token.text)\n",
    "            if fuzzy_game:\n",
    "                extracted_info[\"games\"].add(fuzzy_game)\n",
    "    \n",
    "    return extracted_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea7cc2ed-01fb-4c46-a0bd-44bfa5fd92be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#text = \"J'adore Elden Ring, c'est un excellent RPG. Je cherche un jeu d'action qui ressemble à Hades. J'ai aussi aimé Dark Sols.\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#result = extract_games_and_categories(text)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresult\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "#text = \"J'adore Elden Ring, c'est un excellent RPG. Je cherche un jeu d'action qui ressemble à Hades. J'ai aussi aimé Dark Sols.\"\n",
    "\n",
    "#result = extract_games_and_categories(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e50697d-2c6f-436a-ada6-d3a3d3de8719",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Function for recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae245b6a-eee6-4a84-a1e2-f9573568eb73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "import random\n",
    "\n",
    "# Fonction de recommandation basée sur la similarité\n",
    "def recommend_game(user_query):\n",
    "    #extract infos\n",
    "    extract = extract_games_and_categories(user_query)\n",
    "    # Récupérer les descriptions des jeux extraits\n",
    "    game_descriptions = {}\n",
    "    for game_name in extract['games']:\n",
    "        for game in sample_games:\n",
    "            if game['name'] == game_name:\n",
    "                game_descriptions[game_name] = \"I want an adventure game\"\n",
    "\n",
    "\n",
    "    # Sentiment analysis\n",
    "    sentiment, proba = predict_sentiment(user_query)\n",
    "\n",
    "    recommand_similar_game = True # default\n",
    "    if sentiment=='negative' and proba > 0.70:\n",
    "        recommand_similar_game = False\n",
    "        \n",
    "    if game_descriptions:\n",
    "        description_query = \" \".join(game_descriptions.values())  # Combine toutes les descriptions\n",
    "        user_query = description_query\n",
    "    query_embedding = embedding_model.encode(user_query)\n",
    "    similarities = [\n",
    "        (game[\"name\"], 1 - cosine(query_embedding, game[\"embedding\"]), game.get(\"rating\", 0))\n",
    "        for game in sample_games if \"embedding\" in game\n",
    "    ]\n",
    "\n",
    "    if recommand_similar_game:\n",
    "        similarities.sort(key=lambda x:(x[1], x[2]), reverse=True)\n",
    "    else:\n",
    "        similarities.sort(key=lambda x: (x[1], x[2]), reverse=False)\n",
    "\n",
    "    return similarities[:3]\n",
    "\n",
    "# Test\n",
    "#user_input = \"I don't love war game\"\n",
    "#print(\"Jeux recommandés :\", recommend_game(user_input))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1f1bd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5eb0cbd-dfea-422b-8365-c8bbf5d9742d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChatSession:\n",
    "    def __init__(self, memsize, llm):\n",
    "        self.llm = llm\n",
    "        self.memsize = memsize\n",
    "        self.history = []\n",
    "        self.llmID = \"ASSISTANT:\"\n",
    "        self.userID = \"USER:\"\n",
    "                \n",
    "    def summarizeStrategy(self):\n",
    "        summaryPrompt = \"Résume la conversation suivante en gardant un maximum d'informations fournies par \" + self.userID + \" :\\n\"\n",
    "        lastMessage, lastMessageLength = self.history[-1]\n",
    "        history = \"\"\n",
    "        for m, l in self.history[:-1]:\n",
    "            history += m + \"\\n\"\n",
    "        summary = self.llm.invoke([HumanMessage(content=summaryPrompt + \"\\n\" + history)]).content\n",
    "        summaryLength = self.estimateLength(summary)\n",
    "        if summaryLength + lastMessageLength > self.memsize:\n",
    "            self.fifoStrategy()\n",
    "            return\n",
    "        self.history = [(summary, summaryLength), (lastMessage, lastMessageLength)]\n",
    "    \n",
    "    def fifoStrategy(self):\n",
    "        while self.historyLength() > self.memsize:\n",
    "            self.history = self.history[1:]\n",
    "\n",
    "    def historyLength(self):\n",
    "        return sum(length for _, length in self.history)\n",
    "\n",
    "    def estimateLength(self, text):\n",
    "        return self.llm.get_num_tokens(text)\n",
    "\n",
    "    def addToHistory(self, prompt):\n",
    "        self.history.append((prompt, self.estimateLength(prompt)))\n",
    "        if self.historyLength() > self.memsize:\n",
    "            self.summarizeStrategy()\n",
    "\n",
    "    def chat(self, prompt):\n",
    "        self.addToHistory(self.userID + \" \" + prompt)\n",
    "\n",
    "        recommendations = recommend_game(prompt)\n",
    "        games_list = \", \".join([game[0] for game in recommendations])\n",
    "\n",
    "        chat_prompt = f\"\"\"\n",
    "        L'utilisateur cherche un jeu correspondant à : \"{prompt}\".\n",
    "        Voici les jeux recommandés : {games_list}.\n",
    "        Formule une réponse naturelle et engageante.\n",
    "        \"\"\"\n",
    "\n",
    "        fullPrompt = 'Historique de conversation :\\n'\n",
    "        for msg, _ in self.history:\n",
    "            fullPrompt += msg + \"\\n\"\n",
    "\n",
    "        fullPrompt += \"\\n\" + chat_prompt\n",
    "\n",
    "        resp = self.llm.invoke([HumanMessage(content=fullPrompt)])\n",
    "        content = resp.content\n",
    "        if content.startswith(self.llmID + \": \"):\n",
    "            content = content[len(self.llmID + \": \"):]\n",
    "\n",
    "        self.addToHistory(self.llmID + \" \" + content)\n",
    "        return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8ca7bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " llm = ChatOpenAI(\n",
    "        openai_api_key=\"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\",\n",
    "        openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "        model_name=\"mistralai/mistral-small-3.1-24b-instruct:free\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d64b33c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONTEXT_LENGTH = 500  \n",
    "session = ChatSession(CONTEXT_LENGTH, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0242fe-e8fd-4a5d-b162-08ed1c52525f",
   "metadata": {},
   "source": [
    "### Use Of chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78cb85ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Welcome to the video game recommendation chatbot with memory!\n",
      "\n",
      " Ask me a question (e.g.: “I want an RPG with a good scenario”).\n",
      "\n",
      " Type “exit” to quit.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "👤 Vous :  i want to have an adventure game\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Bot : Bien sûr ! Voici quelques suggestions qui devraient te plaire si tu cherches un jeu d'aventure :\n",
      "\n",
      "1. **The Unlikely Prometheus** : C'est un jeu indépendant avec une histoire captivante et des mécaniques de gameplay intéressantes. Parfait pour les amateurs de mystères et de découvertes.\n",
      "\n",
      "2. **NetGame Adventure** : Si tu aimes les jeux en ligne avec une communauté active, celui-ci pourrait être fait pour toi. Il offre une expérience d'aventure en réseau, plein de défis et de surprises.\n",
      "\n",
      "3. **Trance** : Pour ceux qui cherchent une expérience immersive et psychédélique, Trance est un excellent choix. Ce jeu explore des thèmes de réalité augmentée et de mystère, tout en t'offrant des combats et des puzzles stimulants.\n",
      "\n",
      "Chacun de ces jeux a son propre style unique, donc tu devrais trouver quelque chose qui te convient parfaitement. Bonne aventure ! 🎮✨\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "👤 Vous :  i want to have a killer game\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Bot : D'accord, si tu veux un jeu qui soit véritablement captivant et intense, voici quelques options parmi celles mentionnées qui pourraient te plaire :\n",
      "\n",
      "1. **The Unlikely Prometheus** : Ce jeu est parfait si tu aimes les histoires riches en mystère et en rebondissements. C'est un véritablequête pleine de défis et de surprises qui te tiendra en haleine du début à la fin.\n",
      "\n",
      "2. **NetGame Adventure** : Pour les amateurs de compétition et d'interaction en ligne, c'est le jeu idéal. Avec une communauté active, tu seras sûr de trouver des adversaires redoutables et des défis stimulants.\n",
      "\n",
      "3. **Trance** : Ce jeu est parfait si tu cherches une expérience vraiment immersive et intense. Avec ses thèmes de réalité augmentée et ses puzzles complexes, Trance promet une aventure captivante et psychédélique.\n",
      "\n",
      "Chacun de ces jeux a des éléments qui peuvent rendre ton expérience de jeu vraiment \"killer\". J'espère que tu trouveras celui qui correspond le mieux à tes attentes ! Bonne aventure et amuse-toi bien ! 🎮🔥\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "👤 Vous :  I want to have an adventure game. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Bot : Super ! Si tu cherches un jeu d'aventure, tu as de superbes options à considérer. Chacun de ces jeux a ses propres atouts et peut te plonger dans des univers différents, voici un rappel :\n",
      "\n",
      "1. **The Unlikely Prometheus** : Parfait pour ceux qui aiment les mystères et les découvertes. C'est une expérience indépendante avec une histoire captivante et des mécaniques de gameplay intéressantes.\n",
      "\n",
      "2. **NetGame Adventure** : Idéal si tu préfères les expériences en ligne et interactives. Avec une communauté active, tu pourras relever des défis et t'immerger dans une aventure collaborative pleine de surprises.\n",
      "\n",
      "3. **Trance** : Pour une expérience vraiment immersive et psychédélique, ce jeu explore des thèmes de réalité augmentée avec des puzzles et des combats stimulants. C'est une véritable plongée dans l'inconnu!\n",
      "\n",
      "Chacun de ces jeux t'offrira une aventure inoubliable selon tes préférences. Bonne aventure et amuse-toi bien avec celui que tu choisiras! 🎮✨\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "👤 Vous :  I like cars and I want a game with\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Bot : D'accord, j'ai noté que tu aimes les voitures et que tu cherches un jeu en rapport avec ça. Malheureusement, les jeux que j'ai mentionnés avant ne sont pas spécifiquement axés sur les voitures. Mais je peux te suggérer quelques alternatives qui pourraient bien te plaire :\n",
      "\n",
      "1. **Forza Horizon 5** : Ce jeu te permet de conduire dans des environnements magnifiques et de participer à des courses époustouflantes. C'est parfait pour les amateurs de voitures et d'aventure.\n",
      "\n",
      "2. **Gran Turismo Sport** : Si tu préfères quelque chose de plus réaliste, ce jeu offre une expérience de conduite très immersion avec des graphismes incroyables et des courses compétitives.\n",
      "\n",
      "3. **Need for Speed Heat** : Pour une aventure plus arcade et des défis palpitants, ce jeu te propose des courses nocturnes illégales et des poursuites avec la police.\n",
      "\n",
      "Chacun de ces jeux tiendra compte de ta passion pour les voitures et te proposera une aventure unique et passionnante. Bonne route et amuse-toi bien ! 🏎️🎮\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "👤 Vous :  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "À bientôt !\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Welcome to the video game recommendation chatbot with memory!\")\n",
    "print(\"\\n Ask me a question (e.g.: “I want an RPG with a good scenario”).\")\n",
    "print(\"\\n Type “exit” to quit.\\n\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"👤 Vous : \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"À bientôt !\")\n",
    "        break\n",
    "    \n",
    "    response = session.chat(user_input)\n",
    "    print(f\"🤖 Bot : {response}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
