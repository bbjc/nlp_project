{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a282ac2-1644-4d4e-8b3a-f6e5160c33ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T15:12:28.140123Z",
     "iopub.status.busy": "2025-02-12T15:12:28.139137Z",
     "iopub.status.idle": "2025-02-12T15:12:31.689303Z",
     "shell.execute_reply": "2025-02-12T15:12:31.688068Z",
     "shell.execute_reply.started": "2025-02-12T15:12:28.140068Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.probability import FreqDist\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32797370-2b5f-4280-86d1-99cab7aef0b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T15:28:09.594232Z",
     "iopub.status.busy": "2025-02-12T15:28:09.593751Z",
     "iopub.status.idle": "2025-02-12T15:28:21.180705Z",
     "shell.execute_reply": "2025-02-12T15:28:21.179533Z",
     "shell.execute_reply.started": "2025-02-12T15:28:09.594193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: spa\n",
      "Unique 3-grams: 8209\n",
      "Top 20 3-grams: [(' de', 3707), (' es', 3270), ('de ', 2902), ('os ', 2631), (' qu', 2628), ('es ', 2381), ('que', 2334), ('la ', 2321), (' la', 2310), ('ue ', 2202), (' co', 2038), ('as ', 1882), ('est', 1840), ('do ', 1817), ('en ', 1750), (' un', 1732), (' en', 1728), ('el ', 1679), (' a ', 1581), ('ent', 1544)]\n",
      "38\n",
      "----------------------------------------\n",
      "Language: deu\n",
      "Unique 3-grams: 10094\n",
      "Top 20 3-grams: [('en ', 6424), ('ch ', 5118), ('ich', 5058), ('er ', 4865), ('ein', 4512), ('ie ', 3602), ('cht', 3151), ('sch', 2695), ('st ', 2678), (' de', 2664), ('en.', 2625), ('ine', 2555), ('in ', 2415), (' ei', 2293), ('che', 2072), (' di', 2057), ('ist', 1980), ('der', 1978), (' da', 1917), (' ge', 1893)]\n",
      "38\n",
      "----------------------------------------\n",
      "Language: tur\n",
      "Unique 3-grams: 8151\n",
      "Top 20 3-grams: [('Tom', 2640), (' bi', 2485), ('yor', 2260), ('en ', 1914), ('bir', 1876), ('ir ', 1858), ('om ', 1769), (' ya', 1715), ('in ', 1521), (' ol', 1269), ('lar', 1263), (' ka', 1203), ('iyo', 1160), ('oru', 1093), ('edi', 1082), ('an ', 1075), (' ge', 1034), ('da ', 1029), ('n b', 1014), ('un ', 999)]\n",
      "38\n",
      "----------------------------------------\n",
      "Language: fra\n",
      "Unique 3-grams: 8194\n",
      "Top 20 3-grams: [(' de', 3749), ('es ', 3627), ('de ', 2825), ('le ', 2606), (' pa', 2555), ('ent', 2363), (' qu', 2356), ('ne ', 2351), ('nt ', 2291), ('re ', 2280), (' le', 2269), ('us ', 2263), ('que', 2127), ('e p', 2057), ('ous', 2033), ('est', 1964), ('is ', 1963), ('e d', 1823), ('ue ', 1716), ('e s', 1715)]\n",
      "38\n",
      "----------------------------------------\n",
      "Language: por\n",
      "Unique 3-grams: 8260\n",
      "Top 20 3-grams: [(' de', 2998), ('que', 2812), (' qu', 2768), ('ão ', 2625), ('de ', 2520), (' es', 2231), (' co', 2208), ('ue ', 2122), ('os ', 2052), ('est', 1906), ('do ', 1829), ('om ', 1769), (' se', 1714), ('as ', 1590), (' o ', 1580), (' a ', 1564), (' um', 1521), ('em ', 1504), ('ent', 1445), ('nte', 1436)]\n",
      "38\n",
      "----------------------------------------\n",
      "Language: epo\n",
      "Unique 3-grams: 7693\n",
      "Top 20 3-grams: [('as ', 5713), (' la', 3900), ('la ', 3670), ('is ', 3291), ('est', 2980), (' es', 2722), ('tas', 2624), (' vi', 2432), ('sta', 2421), (' mi', 2058), (' ne', 1928), (' de', 1830), ('Mi ', 1721), ('on ', 1708), ('ne ', 1636), ('aj ', 1575), (', k', 1551), (' ti', 1534), ('on.', 1493), (' al', 1418)]\n",
      "38\n",
      "----------------------------------------\n",
      "Language: ita\n",
      "Unique 3-grams: 5742\n",
      "Top 20 3-grams: [('to ', 2618), ('on ', 2205), ('re ', 2057), ('no ', 1959), (' di', 1940), (' co', 1676), (' ch', 1525), ('che', 1479), ('he ', 1448), ('di ', 1430), ('la ', 1417), ('are', 1412), ('Tom', 1393), (' un', 1358), ('te ', 1343), (' no', 1272), (' è ', 1198), ('ent', 1182), ('o d', 1164), ('o a', 1162)]\n",
      "38\n",
      "----------------------------------------\n",
      "Language: hun\n",
      "Unique 3-grams: 11942\n",
      "Top 20 3-grams: [(' a ', 3336), ('em ', 2253), ('gy ', 2210), (' ne', 1509), (' me', 1367), (' az', 1301), (' sz', 1278), (' va', 1267), ('egy', 1212), (' ho', 1150), ('an ', 1149), ('az ', 1108), (', h', 1083), ('ogy', 1058), ('meg', 1042), ('nem', 1034), ('en ', 1030), (' eg', 1004), ('t a', 992), ('agy', 984)]\n",
      "38\n",
      "----------------------------------------\n",
      "Language: ber\n",
      "Unique 3-grams: 10467\n",
      "Top 20 3-grams: [(' te', 2786), ('ad ', 2270), (' ad', 2226), (' ay', 2219), (' ye', 2067), ('en ', 2001), ('ay ', 1811), ('-nn', 1708), ('d t', 1581), (' n ', 1552), (' ta', 1465), ('eɣ ', 1423), ('ell', 1389), ('eg ', 1359), ('d a', 1319), ('ett', 1280), (' d ', 1205), (' yi', 1191), ('nne', 1115), ('ess', 1072)]\n",
      "38\n",
      "----------------------------------------\n",
      "Language: eng\n",
      "Unique 3-grams: 7353\n",
      "Top 20 3-grams: [(' th', 6060), (' to', 3575), ('he ', 3425), ('Tom', 3162), ('the', 3127), ('om ', 3119), ('to ', 2911), ('hat', 2589), ('at ', 2289), ('ed ', 2132), ('ing', 2131), ('tha', 2115), (' do', 2047), ('is ', 1907), (\"n't\", 1823), (\"'t \", 1812), ('ng ', 1763), ('e t', 1656), (' yo', 1656), ('you', 1655)]\n",
      "38\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def generate_ngrams(text, n):\n",
    "    \"\"\"Generate n-grams from a given text.\"\"\"\n",
    "    return [text[i:i+n] for i in range(len(text) - n + 1)]\n",
    "\n",
    "def analyze_ngrams_per_language(tsv_file, n):\n",
    "    \"\"\"Compute unique n-grams and most frequent ones per language from a TSV file.\"\"\"\n",
    "    df = pd.read_csv(tsv_file, sep='\\t', names=['language', 'text'])\n",
    "    language_ngrams = defaultdict(FreqDist)\n",
    "    \n",
    "    for  _,row in df.iterrows():\n",
    "        ngrams = generate_ngrams(row['text'], n)\n",
    "        language_ngrams[row['language']].update(ngrams)\n",
    "    \n",
    "    results = {}\n",
    "    for language, fdist in language_ngrams.items():\n",
    "        unique_ngrams = len(fdist)\n",
    "        most_common_ngrams = fdist.most_common(20)\n",
    "        results[language] = {\n",
    "            \"unique_ngrams\": unique_ngrams,\n",
    "            \"most_common\": most_common_ngrams,\n",
    "            \"len\": len(ngrams)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "n = 3  \n",
    "tsv_file = \"easy-train.tsv\"  \n",
    "results = analyze_ngrams_per_language(tsv_file, n)\n",
    "\n",
    "\n",
    "for language, data in results.items():\n",
    "    print(f\"Language: {language}\")\n",
    "    print(f\"Unique {n}-grams: {data['unique_ngrams']}\")\n",
    "    print(f\"Top 20 {n}-grams: {data['most_common']}\")\n",
    "    print(data['len'])\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08ed964c-7ec1-430e-977f-ebb410534136",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T14:47:01.477404Z",
     "iopub.status.busy": "2025-02-12T14:47:01.476627Z",
     "iopub.status.idle": "2025-02-12T14:47:17.938987Z",
     "shell.execute_reply": "2025-02-12T14:47:17.937895Z",
     "shell.execute_reply.started": "2025-02-12T14:47:01.477378Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_77/1793832996.py:46: RuntimeWarning: invalid value encountered in log\n",
      "  scores[lang] += np.log(1 / (sum(log_likelihood[lang].values()) + len(log_likelihood[lang])))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted language: spa\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.probability import FreqDist\n",
    "from collections import defaultdict\n",
    "\n",
    "def generate_ngrams(text, n):\n",
    "    \"\"\"Generate n-grams from a given text.\"\"\"\n",
    "    return [text[i:i+n] for i in range(len(text) - n + 1)]\n",
    "\n",
    "def train_naive_bayes(tsv_file, n):\n",
    "    \"\"\"Train a Naïve Bayes classifier for language detection using n-grams.\"\"\"\n",
    "    df = pd.read_csv(tsv_file, sep='\\t', names=['language', 'text'])\n",
    "    language_ngrams = defaultdict(FreqDist)\n",
    "    total_ngrams = 0\n",
    "    language_counts = defaultdict(int)\n",
    "    \n",
    "    # Process each row in the dataset\n",
    "    for _, row in df.iterrows():\n",
    "        ngrams = generate_ngrams(row['text'], n)\n",
    "        language_ngrams[row['language']].update(ngrams)\n",
    "        language_counts[row['language']] += len(ngrams)\n",
    "        total_ngrams += len(ngrams)\n",
    "    \n",
    "    # Compute log probabilities\n",
    "    log_prior = {lang: np.log(count / total_ngrams) for lang, count in language_counts.items()}\n",
    "    log_likelihood = {}\n",
    "    \n",
    "    for lang, fdist in language_ngrams.items():\n",
    "        total_lang_ngrams = sum(fdist.values())\n",
    "        log_likelihood[lang] = {ngram: np.log((count + 1) / (total_lang_ngrams + len(fdist))) for ngram, count in fdist.items()}\n",
    "    \n",
    "    return log_prior, log_likelihood\n",
    "\n",
    "def predict_language(text, n, log_prior, log_likelihood):\n",
    "    \"\"\"Predict the language of a given text using the trained Naïve Bayes model.\"\"\"\n",
    "    ngrams = generate_ngrams(text, n)\n",
    "    scores = {}\n",
    "    \n",
    "    for lang in log_prior:\n",
    "        scores[lang] = log_prior[lang]\n",
    "        for ngram in ngrams:\n",
    "            if ngram in log_likelihood[lang]:\n",
    "                scores[lang] += log_likelihood[lang][ngram]\n",
    "            else:\n",
    "                scores[lang] += np.log(1 / (sum(log_likelihood[lang].values()) + len(log_likelihood[lang])))\n",
    "    \n",
    "    return max(scores, key=scores.get)\n",
    "\n",
    "# Example usage\n",
    "n = 10  # Change this for different n-gram sizes\n",
    "tsv_file = \"easy-train.tsv\"  # Update with actual file path\n",
    "log_prior, log_likelihood = train_naive_bayes(tsv_file, n)\n",
    "\n",
    "# Test the model\n",
    "test_sentence = \"This is a test sentence.\"\n",
    "predicted_language = predict_language(test_sentence, n, log_prior, log_likelihood)\n",
    "print(f\"Predicted language: {predicted_language}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
